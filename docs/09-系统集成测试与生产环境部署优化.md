# 第09章：系统集成测试与生产环境部署优化

本章介绍系统测试和部署相关内容。

## 一、功能测试

### 1. 配置测试

```bash
python test_settings.py
python test_env.py
```

### 2. 模块测试

```bash
# 测试LLM客户端
python services/llm_client.py

# 测试向量存储
python services/vector_store.py

# 测试天气服务
python services/weather_tools.py

# 测试文档处理
python utils/document_processor.py
```

### 3. 集成测试

```bash
# 启动应用
streamlit run app.py

# 测试流程：
# 1. 上传文档
# 2. 等待向量化完成
# 3. 提问测试
# 4. 查看聊天历史
# 5. 导出记录
```

## 二、生产环境部署

### 方式一：Docker部署

创建 `Dockerfile`：

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY pyproject.toml .
RUN pip install -e .

COPY . .

EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

构建和运行：

```bash
docker build -t smart-qa-app .
docker run -p 8501:8501 --env-file .env smart-qa-app
```

### 方式二：Streamlit Cloud部署

1. 将代码推送到GitHub
2. 访问 https://share.streamlit.io/
3. 连接GitHub仓库
4. 配置环境变量
5. 部署

### 方式三：本地生产运行

```bash
# 安装依赖
pip install -e .

# 配置环境变量
cp .env.example .env
# 编辑 .env 填入API密钥

# 运行
streamlit run app.py --server.port=8501
```

## 三、性能优化建议

### 1. 向量库优化

- 使用FAISS的IndexIVFFlat代替Flat（大规模数据）
- 定期清理过期缓存
- 批量处理文档上传

### 2. LLM调用优化

- 合理设置temperature和max_tokens
- 使用流式输出提升用户体验
- 实现请求限流避免超限

### 3. 日志与监控

- 生产环境设置 LOG_LEVEL=INFO
- 使用 logging.handlers.RotatingFileHandler
- 监控API调用次数和费用

## 四、常见问题排查

### Q1: 向量存储未准备

**原因**：文档上传后未自动处理

**解决**：检查文档格式是否支持，查看日志错误信息

### Q2: LLM调用失败

**原因**：API密钥错误或网络问题

**解决**：检查.env配置，测试网络连接

### Q3: 嵌入模型超限

**原因**：文档片段过长

**解决**：调整CHUNK_SIZE参数，项目已自动限制2000字符

## 五、项目总结

### 完成的功能

✅ 双模式LLM支持（Ollama + 阿里云百炼）
✅ FAISS向量存储与语义检索
✅ Agentic RAG智能路由系统
✅ ReAct多步推理框架
✅ 多格式文档处理
✅ 天气查询工具集成
✅ 聊天历史管理
✅ Streamlit Web界面

### 技术栈回顾

- **前端**：Streamlit
- **AI框架**：LangChain
- **向量库**：FAISS
- **LLM**：Ollama / 阿里云百炼
- **文档处理**：pypdf, python-docx, unstructured
- **外部API**：高德地图天气API

### 扩展方向

1. **功能扩展**
   - 支持更多文档格式（Excel、PPT等）
   - 添加用户认证和权限管理
   - 实现多知识库切换
   - 添加语音输入输出

2. **性能优化**
   - 接入Redis缓存
   - 实现异步处理
   - 添加GPU加速
   - 优化向量索引结构

3. **部署优化**
   - Kubernetes集群部署
   - 负载均衡配置
   - 监控告警系统
   - 自动化CI/CD

## 六、学习资源

- LangChain官方文档：https://python.langchain.com/
- FAISS文档：https://faiss.ai/
- Streamlit文档：https://docs.streamlit.io/
- Ollama文档：https://ollama.com/

---

## 🎉 教程完结

恭喜你完成了整个系列教程！你已经掌握了从零构建生产级Agentic RAG系统的完整技能。

**接下来建议**：
1. 基于这个项目做定制化开发
2. 尝试接入其他LLM模型（GPT-4、Claude等）
3. 添加更多工具函数扩展Agent能力
4. 将项目部署到生产环境实际使用

祝你在AI应用开发的道路上越走越远！🚀
