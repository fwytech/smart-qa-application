# ç¬¬16è®²ï¼šå·¥å…·ç±»å®ç° - å¤©æ°”æŸ¥è¯¢ä¸æ–‡æ¡£å¤„ç†

> **æœ¬è®²ç›®æ ‡**ï¼šæŒæ¡å…·ä½“å·¥å…·ç±»çš„å®ç°ï¼ŒåŒ…æ‹¬å¤–éƒ¨APIé›†æˆå’Œæ–‡æ¡£å¤„ç†æµç¨‹

## ä¸€ã€Agentçš„å·¥å…·ä½“ç³»

æœ¬è®²å®ç°ä¸¤ä¸ªæ ¸å¿ƒå·¥å…·ï¼š

**å·¥å…·ç³»ç»Ÿæ¶æ„**ï¼š
```mermaid
graph TD
    A[Agent] --> B[WeatherTools å¤©æ°”æŸ¥è¯¢]
    A --> C[DocumentProcessor æ–‡æ¡£å¤„ç†]
    B --> D[é«˜å¾·å¤©æ°”API]
    C --> E[LangChainæ–‡æ¡£åŠ è½½å™¨]
    C --> F[ç¼“å­˜ç³»ç»Ÿ]
    E --> G[PDF/TXT/MD/DOCX]
```

**ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸¤ä¸ªå·¥å…·ï¼Ÿ**

| å·¥å…· | ä½œç”¨ | éš¾ç‚¹ | æ•™å­¦ä»·å€¼ |
|------|------|------|----------|
| **WeatherTools** | å¤–éƒ¨APIé›†æˆç¤ºä¾‹ | APIè°ƒç”¨ã€é”™è¯¯å¤„ç†ã€æ•°æ®æ ¼å¼åŒ– | å­¦ä¹ ç¬¬ä¸‰æ–¹æœåŠ¡é›†æˆ |
| **DocumentProcessor** | æ–‡æ¡£å¤„ç†æ ¸å¿ƒ | å¤šæ ¼å¼æ”¯æŒã€ç¼“å­˜ä¼˜åŒ–ã€å…ƒæ•°æ®ç®¡ç† | å­¦ä¹ RAGæ•°æ®å‡†å¤‡ |

## äºŒã€æ–‡ä»¶ç»“æ„æ¦‚è§ˆ

æˆ‘ä»¬æœ‰ä¸¤ä¸ªæ–‡ä»¶ï¼ˆå…±653è¡Œï¼‰ï¼š

**weather_tools.pyï¼ˆ310è¡Œï¼‰**ï¼š
- `WeatherService`ç±»ï¼šæ ¸å¿ƒæœåŠ¡ï¼ˆ265è¡Œï¼‰
  - åŸå¸‚ä»£ç æŸ¥è¯¢
  - å½“å‰å¤©æ°”æŸ¥è¯¢
  - å¤©æ°”é¢„æŠ¥æŸ¥è¯¢
  - ä¿¡æ¯æ ¼å¼åŒ–
- `WeatherTools`ç±»ï¼šå·¥å…·åŒ…è£…ï¼ˆ35è¡Œï¼‰

**document_processor.pyï¼ˆ343è¡Œï¼‰**ï¼š
- `DocumentProcessor`ç±»ï¼šå®Œæ•´æ–‡æ¡£å¤„ç†
  - æ–‡ä»¶ä¸Šä¼ å¤„ç†
  - å¤šæ ¼å¼åŠ è½½å™¨ï¼ˆPDF/TXT/MD/DOCXï¼‰
  - ç¼“å­˜æœºåˆ¶ï¼ˆMD5å“ˆå¸Œï¼‰
  - æ‰¹é‡å¤„ç†
  - ç»Ÿè®¡ä¿¡æ¯

## ä¸‰ã€ä»£ç å®ç°è¯¦è§£

æˆ‘ä»¬å°†ä»£ç æ‹†åˆ†æˆ5ä¸ªéƒ¨åˆ†è®²è§£ã€‚

### ç¬¬ä¸€éƒ¨åˆ†ï¼šå¤©æ°”æœåŠ¡åˆå§‹åŒ–å’ŒåŸå¸‚ä»£ç æŸ¥è¯¢ï¼ˆweather_tools.py 1-62è¡Œï¼‰
**ä»£ç æ–‡ä»¶ï¼š** `study-agentic-rag/03-smart-qa-application/services/weather_tools.py`


å¤©æ°”APIé€šå¸¸éœ€è¦åŸå¸‚ä»£ç ï¼ˆè€Œä¸æ˜¯åŸå¸‚åç§°ï¼‰ï¼Œè¿™éƒ¨åˆ†å®ç°åŸå¸‚åç§°åˆ°ä»£ç çš„è½¬æ¢ã€‚

<details>
<summary>ç‚¹å‡»å±•å¼€ä»£ç </summary>

```python
import requests
import json
import logging
from typing import Dict, Optional, Any, List
from datetime import datetime
from config.settings import Settings

logger = logging.getLogger(__name__)

class WeatherService:
    """å¤©æ°”æŸ¥è¯¢æœåŠ¡ç±»"""

    def __init__(self):
        self.settings = Settings()
        self.api_key = self.settings.WEATHER_API_KEY
        self.weather_url = self.settings.WEATHER_API_URL
        self.city_url = self.settings.WEATHER_CITY_URL

        # åŸå¸‚ä»£ç ç¼“å­˜
        self.city_cache = {}

    def get_city_code(self, city_name: str) -> Optional[str]:
        """è·å–åŸå¸‚ä»£ç """
        try:
            # æ£€æŸ¥ç¼“å­˜
            if city_name in self.city_cache:
                return self.city_cache[city_name]

            # æ„å»ºè¯·æ±‚URL
            url = f"{self.city_url}"
            params = {
                "keywords": city_name,
                "subdistrict": 0,
                "key": self.api_key,
                "extensions": "base"
            }

            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()

            data = response.json()

            if data.get("status") == "1" and data.get("districts"):
                # è·å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„åŸå¸‚
                districts = data["districts"]
                if districts and len(districts) > 0:
                    city_code = districts[0].get("adcode")
                    if city_code:
                        # ç¼“å­˜ç»“æœ
                        self.city_cache[city_name] = city_code
                        logger.info(f"è·å–åŸå¸‚ä»£ç æˆåŠŸ: {city_name} -> {city_code}")
                        return city_code

            logger.warning(f"æœªæ‰¾åˆ°åŸå¸‚: {city_name}")
            return None

        except requests.RequestException as e:
            logger.error(f"è·å–åŸå¸‚ä»£ç å¤±è´¥: {str(e)}")
            return None
        except Exception as e:
            logger.error(f"è·å–åŸå¸‚ä»£ç å‡ºé”™: {str(e)}")
            return None
```

</details>

**ä¸ºä»€ä¹ˆè¿™ä¹ˆå†™ï¼Ÿ**

1. **ä¸ºä»€ä¹ˆéœ€è¦åŸå¸‚ä»£ç ç¼“å­˜ï¼Ÿ**
   ```python
   self.city_cache = {}  # å†…å­˜ç¼“å­˜
   if city_name in self.city_cache:
       return self.city_cache[city_name]
   ```
   - **æ€§èƒ½ä¼˜åŒ–**ï¼šé¿å…é‡å¤è°ƒç”¨åŸå¸‚æŸ¥è¯¢API
   - **èŠ‚çœé…é¢**ï¼šå‡å°‘APIè°ƒç”¨æ¬¡æ•°
   - **åŠ é€Ÿå“åº”**ï¼šç¼“å­˜å‘½ä¸­åç«‹å³è¿”å›

2. **ä¸ºä»€ä¹ˆç”¨`timeout=10`ï¼Ÿ**
   ```python
   response = requests.get(url, params=params, timeout=10)
   ```
   - é˜²æ­¢APIæ— å“åº”å¯¼è‡´ç¨‹åºæŒ‚èµ·
   - 10ç§’æ˜¯åˆç†çš„è¶…æ—¶æ—¶é—´ï¼ˆç½‘ç»œæ­£å¸¸1-2ç§’å³å¯ï¼‰
   - è¶…æ—¶åæŠ›å‡º`requests.Timeout`å¼‚å¸¸

3. **ä¸ºä»€ä¹ˆç”¨`raise_for_status()`ï¼Ÿ**
   ```python
   response.raise_for_status()
   ```
   - æ£€æŸ¥HTTPçŠ¶æ€ç ï¼ˆ200-299ä¸ºæˆåŠŸï¼‰
   - 4xx/5xxä¼šæŠ›å‡º`requests.HTTPError`
   - ç»Ÿä¸€å¼‚å¸¸å¤„ç†æµç¨‹

4. **ä¸ºä»€ä¹ˆè¿”å›`None`è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸ï¼Ÿ**
   ```python
   if not city_code:
       logger.warning(f"æœªæ‰¾åˆ°åŸå¸‚: {city_name}")
       return None  # è€Œä¸æ˜¯raise
   ```
   - åŸå¸‚æœªæ‰¾åˆ°æ˜¯æ­£å¸¸ä¸šåŠ¡åœºæ™¯ï¼ˆç”¨æˆ·è¾“é”™ï¼‰
   - è¿”å›`None`è®©è°ƒç”¨æ–¹å†³å®šå¦‚ä½•å¤„ç†
   - ç½‘ç»œé”™è¯¯æ‰æŠ›å‡ºå¼‚å¸¸

### ç¬¬äºŒéƒ¨åˆ†ï¼šå½“å‰å¤©æ°”å’Œé¢„æŠ¥æŸ¥è¯¢ï¼ˆweather_tools.py 64-145è¡Œï¼‰
**ä»£ç æ–‡ä»¶ï¼š** `study-agentic-rag/03-smart-qa-application/services/weather_tools.py`


è¿™éƒ¨åˆ†è°ƒç”¨é«˜å¾·å¤©æ°”APIè·å–å¤©æ°”ä¿¡æ¯ã€‚

<details>
<summary>ç‚¹å‡»å±•å¼€ä»£ç </summary>

```python
    def get_current_weather(self, city_name: str) -> str:
        """è·å–å½“å‰å¤©æ°”"""
        try:
            city_code = self.get_city_code(city_name)
            if not city_code:
                return f"æŠ±æ­‰ï¼Œæ— æ³•æ‰¾åˆ°åŸå¸‚ '{city_name}' çš„ä¿¡æ¯ã€‚è¯·æ£€æŸ¥åŸå¸‚åç§°æ˜¯å¦æ­£ç¡®ã€‚"

            # æ„å»ºè¯·æ±‚URL
            params = {
                "city": city_code,
                "key": self.api_key,
                "extensions": "base"  # base=å®å†µå¤©æ°”
            }

            response = requests.get(self.weather_url, params=params, timeout=10)
            response.raise_for_status()

            data = response.json()

            if data.get("status") == "1" and data.get("lives"):
                weather_info = data["lives"][0]

                # æ ¼å¼åŒ–å¤©æ°”ä¿¡æ¯
                result = self._format_current_weather(weather_info, city_name)
                logger.info(f"è·å–å½“å‰å¤©æ°”æˆåŠŸ: {city_name}")
                return result
            else:
                error_msg = data.get("info", "æœªçŸ¥é”™è¯¯")
                logger.warning(f"è·å–å½“å‰å¤©æ°”å¤±è´¥: {error_msg}")
                return f"è·å–å¤©æ°”ä¿¡æ¯å¤±è´¥: {error_msg}"

        except requests.RequestException as e:
            error_msg = f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
            logger.error(f"è·å–å½“å‰å¤©æ°”å¤±è´¥: {error_msg}")
            return f"è·å–å¤©æ°”ä¿¡æ¯å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        except Exception as e:
            error_msg = f"è·å–å½“å‰å¤©æ°”å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            return f"è·å–å¤©æ°”ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

    def get_weather_forecast(self, city_name: str, days: int = 3) -> str:
        """è·å–å¤©æ°”é¢„æŠ¥"""
        try:
            if days < 1 or days > 7:
                return "é¢„æŠ¥å¤©æ•°å¿…é¡»åœ¨1-7å¤©ä¹‹é—´ã€‚"

            city_code = self.get_city_code(city_name)
            if not city_code:
                return f"æŠ±æ­‰ï¼Œæ— æ³•æ‰¾åˆ°åŸå¸‚ '{city_name}' çš„ä¿¡æ¯ã€‚è¯·æ£€æŸ¥åŸå¸‚åç§°æ˜¯å¦æ­£ç¡®ã€‚"

            # æ„å»ºè¯·æ±‚URL
            params = {
                "city": city_code,
                "key": self.api_key,
                "extensions": "all"  # all=é¢„æŠ¥å¤©æ°”
            }

            response = requests.get(self.weather_url, params=params, timeout=10)
            response.raise_for_status()

            data = response.json()

            if data.get("status") == "1" and data.get("forecasts"):
                forecast_info = data["forecasts"][0]

                # æ ¼å¼åŒ–é¢„æŠ¥ä¿¡æ¯
                result = self._format_weather_forecast(forecast_info, city_name, days)
                logger.info(f"è·å–å¤©æ°”é¢„æŠ¥æˆåŠŸ: {city_name}, å¤©æ•°: {days}")
                return result
            else:
                error_msg = data.get("info", "æœªçŸ¥é”™è¯¯")
                logger.warning(f"è·å–å¤©æ°”é¢„æŠ¥å¤±è´¥: {error_msg}")
                return f"è·å–å¤©æ°”é¢„æŠ¥å¤±è´¥: {error_msg}"

        except requests.RequestException as e:
            error_msg = f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
            logger.error(f"è·å–å¤©æ°”é¢„æŠ¥å¤±è´¥: {error_msg}")
            return f"è·å–å¤©æ°”é¢„æŠ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        except Exception as e:
            error_msg = f"è·å–å¤©æ°”é¢„æŠ¥å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            return f"è·å–å¤©æ°”é¢„æŠ¥æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
```

</details>

**ä¸ºä»€ä¹ˆè¿™ä¹ˆå†™ï¼Ÿ**

1. **ä¸ºä»€ä¹ˆå‚æ•°ç”¨`extensions="base"`å’Œ`extensions="all"`ï¼Ÿ**

```python
   # å½“å‰å¤©æ°”
   params = {"extensions": "base"}
   # å¤©æ°”é¢„æŠ¥
   params = {"extensions": "all"}
```
   - é«˜å¾·APIçš„è®¾è®¡ï¼š`base`è¿”å›å®å†µï¼Œ`all`è¿”å›é¢„æŠ¥
   - åŒä¸€ä¸ªæ¥å£ï¼Œä¸åŒå‚æ•°è·å–ä¸åŒæ•°æ®
   - èŠ‚çœå­¦ä¹ æˆæœ¬ï¼ˆåªéœ€è®°ä½ä¸€ä¸ªæ¥å£ï¼‰

2. **ä¸ºä»€ä¹ˆè¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯dictï¼Ÿ**

```python
   return result  # å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯dict
```
```
   - **Agentéœ€è¦æ–‡æœ¬**ï¼šLLMåªèƒ½ç†è§£è‡ªç„¶è¯­è¨€
   - æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²æ›´æ˜“è¯»ï¼š
```
     ğŸ™ï¸ **åŒ—äº¬** å½“å‰å¤©æ°”
     ğŸŒ¤ï¸ **å¤©æ°”çŠ¶å†µ**: æ™´
     ğŸŒ¡ï¸ **æ°”æ¸©**: 25Â°C
```
   - å¦‚æœè¿”å›dictï¼ŒAgentè¿˜éœ€è¦è‡ªå·±æ ¼å¼åŒ–
```
3. **ä¸ºä»€ä¹ˆé™åˆ¶`days`åœ¨1-7å¤©ï¼Ÿ**
   ```python
   if days < 1 or days > 7:
       return "é¢„æŠ¥å¤©æ•°å¿…é¡»åœ¨1-7å¤©ä¹‹é—´ã€‚"
   ```

   - é«˜å¾·APIåªæä¾›7å¤©é¢„æŠ¥
   - æå‰éªŒè¯ï¼Œé¿å…æ— æ•ˆè¯·æ±‚
   - ç»™ç”¨æˆ·æ˜ç¡®çš„åé¦ˆ

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¤©æ°”ä¿¡æ¯æ ¼å¼åŒ–ï¼ˆweather_tools.py 147-273è¡Œï¼‰
**ä»£ç æ–‡ä»¶ï¼š** `03-smart-qa-application/services/weather_tools.py`


è¿™éƒ¨åˆ†å°†APIè¿”å›çš„JSONè½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„æ–‡æœ¬ã€‚

<details>
<summary>ç‚¹å‡»å±•å¼€ä»£ç ï¼ˆä»…å±•ç¤ºå½“å‰å¤©æ°”æ ¼å¼åŒ–ï¼‰</summary>

```python
    def _format_current_weather(self, weather_data: Dict[str, Any], city_name: str) -> str:
        """æ ¼å¼åŒ–å½“å‰å¤©æ°”ä¿¡æ¯"""
        try:
            province = weather_data.get("province", "")
            city = weather_data.get("city", city_name)
            weather = weather_data.get("weather", "")
            temperature = weather_data.get("temperature", "")
            winddirection = weather_data.get("winddirection", "")
            windpower = weather_data.get("windpower", "")
            humidity = weather_data.get("humidity", "")
            reporttime = weather_data.get("reporttime", "")

            # æ„å»ºæ ¼å¼åŒ–è¾“å‡º
            result = f"ğŸ™ï¸ **{province} {city}** å½“å‰å¤©æ°”\n\n"
            result += f"ğŸŒ¤ï¸ **å¤©æ°”çŠ¶å†µ**: {weather}\n"
            result += f"ğŸŒ¡ï¸ **æ°”æ¸©**: {temperature}Â°C\n"
            result += f"ğŸ’¨ **é£å‘é£åŠ›**: {winddirection} {windpower}\n"
            result += f"ğŸ’§ **æ¹¿åº¦**: {humidity}%\n"
            result += f"ğŸ“… **å‘å¸ƒæ—¶é—´**: {reporttime}\n"

            # æ·»åŠ å¤©æ°”å»ºè®®
            result += "\nğŸ’¡ **æ¸©é¦¨æç¤º**:\n"

            if temperature and temperature.isdigit():
                temp = int(temperature)
                if temp < 10:
                    result += "â€¢ å¤©æ°”è¾ƒå†·ï¼Œè¯·æ³¨æ„ä¿æš–ã€‚\n"
                elif temp > 30:
                    result += "â€¢ å¤©æ°”è¾ƒçƒ­ï¼Œè¯·æ³¨æ„é˜²æš‘ã€‚\n"
                else:
                    result += "â€¢ å¤©æ°”èˆ’é€‚ï¼Œé€‚åˆå¤–å‡ºã€‚\n"

            if humidity and humidity.isdigit():
                hum = int(humidity)
                if hum > 80:
                    result += "â€¢ æ¹¿åº¦è¾ƒé«˜ï¼Œæ³¨æ„é˜²æ½®ã€‚\n"
                elif hum < 30:
                    result += "â€¢ æ¹¿åº¦è¾ƒä½ï¼Œæ³¨æ„è¡¥æ°´ã€‚\n"

            return result

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–å½“å‰å¤©æ°”ä¿¡æ¯å¤±è´¥: {str(e)}")
            return f"å¤©æ°”æ•°æ®æ ¼å¼åŒ–å¤±è´¥: {str(e)}"
```

</details>

**ä¸ºä»€ä¹ˆè¿™ä¹ˆå†™ï¼Ÿ**

1. **ä¸ºä»€ä¹ˆç”¨Emojiç¬¦å·ï¼Ÿ**
   ```python
   result = f"ğŸ™ï¸ **{province} {city}** å½“å‰å¤©æ°”\n\n"
   result += f"ğŸŒ¤ï¸ **å¤©æ°”çŠ¶å†µ**: {weather}\n"
   result += f"ğŸŒ¡ï¸ **æ°”æ¸©**: {temperature}Â°C\n"
   ```
   - æå‡å¯è¯»æ€§å’Œè¶£å‘³æ€§
   - è§†è§‰ä¸ŠåŒºåˆ†ä¸åŒå­—æ®µ
   - ç”¨æˆ·ä½“éªŒæ›´å¥½

2. **ä¸ºä»€ä¹ˆæ·»åŠ æ¸©é¦¨æç¤ºï¼Ÿ**
   ```python
   if temp < 10:
       result += "â€¢ å¤©æ°”è¾ƒå†·ï¼Œè¯·æ³¨æ„ä¿æš–ã€‚\n"
   elif temp > 30:
       result += "â€¢ å¤©æ°”è¾ƒçƒ­ï¼Œè¯·æ³¨æ„é˜²æš‘ã€‚\n"
   ```
   - å¢åŠ å·¥å…·çš„ä»·å€¼ï¼ˆä¸åªæ˜¯æŸ¥å¤©æ°”ï¼Œè¿˜ç»™å»ºè®®ï¼‰
   - æå‡ç”¨æˆ·ä½“éªŒ
   - å±•ç¤ºå·¥å…·çš„æ™ºèƒ½æ€§

3. **ä¸ºä»€ä¹ˆç”¨`temperature.isdigit()`åˆ¤æ–­ï¼Ÿ**
   ```python
   if temperature and temperature.isdigit():
       temp = int(temperature)
   ```
   - **é˜²å¾¡æ€§ç¼–ç¨‹**ï¼šAPIè¿”å›çš„å¯èƒ½ä¸æ˜¯æ•°å­—
   - é¿å…`int("æ™´")`å¯¼è‡´å¼‚å¸¸
   - ç¡®ä¿ä»£ç å¥å£®æ€§

4. æµ‹è¯•åŠŸèƒ½

   ```python
   if __name__ == "__main__":
       """
       å¤©æ°”æœåŠ¡æµ‹è¯•ä»£ç 
       è¿è¡Œæ–¹æ³•ï¼špython services/weather_tools.py
       """
       import logging
       
       # é…ç½®æ—¥å¿—æ˜¾ç¤º
       logging.basicConfig(
           level=logging.INFO,
           format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
           datefmt='%Y-%m-%d %H:%M:%S'
       )
       
       print("ğŸŒ¤ï¸ å¤©æ°”æœåŠ¡æµ‹è¯•å¼€å§‹...")
       print("=" * 50)
       
       # åˆ›å»ºå¤©æ°”æœåŠ¡å®ä¾‹
       weather_service = WeatherService()
       
       # æµ‹è¯•1ï¼šè·å–åŸå¸‚ä»£ç 
       print("\nğŸ“ æµ‹è¯•1ï¼šè·å–åŸå¸‚ä»£ç ")
       print("-" * 30)
       test_cities = ["åŒ—äº¬", "ä¸Šæµ·"]
       
       for city in test_cities:
           city_code = weather_service.get_city_code(city)
           if city_code:
               print(f"âœ… {city}: {city_code}")
           else:
               print(f"âŒ {city}: æœªæ‰¾åˆ°åŸå¸‚ä»£ç ")
       
       # æµ‹è¯•2ï¼šè·å–å½“å‰å¤©æ°”
       print("\nğŸŒ¡ï¸ æµ‹è¯•2ï¼šè·å–å½“å‰å¤©æ°”")
       print("-" * 30)
       
       for city in test_cities[:3]:  # åªæµ‹è¯•å‰3ä¸ªåŸå¸‚
           print(f"\nğŸŒ {city}å½“å‰å¤©æ°”ï¼š")
           weather_info = weather_service.get_current_weather(city)
           print(weather_info)
           print("-" * 30)
       
       # æµ‹è¯•3ï¼šè·å–å¤©æ°”é¢„æŠ¥
       print("\nğŸ“… æµ‹è¯•3ï¼šè·å–å¤©æ°”é¢„æŠ¥")
       print("-" * 30)
       
       for city in test_cities[:2]:  # åªæµ‹è¯•å‰2ä¸ªåŸå¸‚
           for days in [1, 3, 5]:
               print(f"\nğŸŒˆ {city}æœªæ¥{days}å¤©é¢„æŠ¥ï¼š")
               forecast_info = weather_service.get_weather_forecast(city, days)
               print(forecast_info)
               print("-" * 30)
       
       # æµ‹è¯•4ï¼šé”™è¯¯å¤„ç†
       print("\nâš ï¸ æµ‹è¯•4ï¼šé”™è¯¯å¤„ç†")
       print("-" * 30)
       
       # æµ‹è¯•ä¸å­˜åœ¨çš„åŸå¸‚
       fake_city = "ä¸å­˜åœ¨çš„åŸå¸‚123"
       result = weather_service.get_current_weather(fake_city)
       print(f"æŸ¥è¯¢ä¸å­˜åœ¨çš„åŸå¸‚ '{fake_city}':")
       print(result)
       
       # æµ‹è¯•æ— æ•ˆçš„é¢„æŠ¥å¤©æ•°
       result = weather_service.get_weather_forecast("åŒ—äº¬", 0)
       print(f"\né¢„æŠ¥å¤©æ•°ä¸º0ï¼š")
       print(result)
       
       result = weather_service.get_weather_forecast("åŒ—äº¬", 10)
       print(f"\né¢„æŠ¥å¤©æ•°ä¸º10ï¼š")
       print(result)
       
       print("\n" + "=" * 50)
       print("ğŸ‰ å¤©æ°”æœåŠ¡æµ‹è¯•å®Œæˆï¼")
       print("\nğŸ’¡ æµ‹è¯•ç»“æœè¯´æ˜ï¼š")
       print("â€¢ âœ… è¡¨ç¤ºåŠŸèƒ½æ­£å¸¸")
       print("â€¢ âŒ è¡¨ç¤ºæœ‰é”™è¯¯æˆ–æ‰¾ä¸åˆ°æ•°æ®")
       print("â€¢ å¦‚æœçœ‹åˆ°å¤©æ°”ä¿¡æ¯ï¼Œè¯´æ˜APIè°ƒç”¨æˆåŠŸ")
       print("â€¢ å¦‚æœçœ‹åˆ°é”™è¯¯æç¤ºï¼Œè¯´æ˜é”™è¯¯å¤„ç†æœºåˆ¶å·¥ä½œæ­£å¸¸")
   ```

5. è¿è¡Œä»£ç 

   ```bash
   cd agentic-rag-case\03-smart-qa-application
   uv run python services/weather_tools.py
   ```

é¢„æœŸç»“æœï¼š

```
ğŸŒ¤ï¸ å¤©æ°”æœåŠ¡æµ‹è¯•å¼€å§‹...
==================================================

ğŸ“ æµ‹è¯•1ï¼šè·å–åŸå¸‚ä»£ç 
------------------------------
2025-11-11 18:09:22 - __main__ - INFO - è·å–åŸå¸‚ä»£ç æˆåŠŸ: åŒ—äº¬ -> 110000
âœ… åŒ—äº¬: 110000
2025-11-11 18:09:23 - __main__ - INFO - è·å–åŸå¸‚ä»£ç æˆåŠŸ: ä¸Šæµ· -> 310000
âœ… ä¸Šæµ·: 310000

ğŸŒ¡ï¸ æµ‹è¯•2ï¼šè·å–å½“å‰å¤©æ°”        
------------------------------

ğŸŒ åŒ—äº¬å½“å‰å¤©æ°”ï¼š
2025-11-11 18:09:23 - __main__ - INFO - è·å–å½“å‰å¤©æ°”æˆåŠŸ: åŒ—äº¬
ğŸ™ï¸ **åŒ—äº¬ åŒ—äº¬å¸‚** å½“å‰å¤©æ°”

ğŸŒ¤ï¸ **å¤©æ°”çŠ¶å†µ**: æ™´        
ğŸŒ¡ï¸ **æ°”æ¸©**: 10Â°C
ğŸ’¨ **é£å‘é£åŠ›**: ä¸œåŒ— â‰¤3   
ğŸ’§ **æ¹¿åº¦**: 66%
ğŸ“… **å‘å¸ƒæ—¶é—´**: 2025-11-11 18:07:39

ğŸ’¡ **æ¸©é¦¨æç¤º**:
â€¢ å¤©æ°”èˆ’é€‚ï¼Œé€‚åˆå¤–å‡ºã€‚

------------------------------

ğŸŒ ä¸Šæµ·å½“å‰å¤©æ°”ï¼š
2025-11-11 18:09:24 - __main__ - INFO - è·å–å½“å‰å¤©æ°”æˆåŠŸ: ä¸Šæµ·
ğŸ™ï¸ **ä¸Šæµ· ä¸Šæµ·å¸‚** å½“å‰å¤©æ°”

ğŸŒ¤ï¸ **å¤©æ°”çŠ¶å†µ**: é˜´
ğŸŒ¡ï¸ **æ°”æ¸©**: 16Â°C
ğŸ’¨ **é£å‘é£åŠ›**: è¥¿ â‰¤3
ğŸ’§ **æ¹¿åº¦**: 62%
ğŸ“… **å‘å¸ƒæ—¶é—´**: 2025-11-11 18:03:04

ğŸ’¡ **æ¸©é¦¨æç¤º**:
â€¢ å¤©æ°”èˆ’é€‚ï¼Œé€‚åˆå¤–å‡ºã€‚

------------------------------

ğŸ“… æµ‹è¯•3ï¼šè·å–å¤©æ°”é¢„æŠ¥
------------------------------

ğŸŒˆ åŒ—äº¬æœªæ¥1å¤©é¢„æŠ¥ï¼š
2025-11-11 18:09:25 - __main__ - INFO - è·å–å¤©æ°”é¢„æŠ¥æˆåŠŸ: åŒ—äº¬, å¤©æ•°: 1
ğŸ™ï¸ **åŒ—äº¬ åŒ—äº¬å¸‚** æœªæ¥1å¤©å¤©æ°”é¢„æŠ¥

ğŸ“… **å‘å¸ƒæ—¶é—´**: 2025-11-11 18:07:39

ğŸ“… **2025-11-11** (2)
ğŸŒ¤ï¸ **å¤©æ°”**: ç™½å¤©æ™´ï¼Œå¤œé—´å¤šäº‘
ğŸŒ¡ï¸ **æ¸©åº¦**: ç™½å¤©14Â°Cï¼Œå¤œé—´3Â°C
ğŸ’¨ **é£åŠ›**: ç™½å¤©ä¸œåŒ—1-3ï¼Œå¤œé—´ä¸œåŒ—1-3

------------------------------

ğŸŒˆ åŒ—äº¬æœªæ¥3å¤©é¢„æŠ¥ï¼š
2025-11-11 18:09:25 - __main__ - INFO - è·å–å¤©æ°”é¢„æŠ¥æˆåŠŸ: åŒ—äº¬, å¤©æ•°: 3
ğŸ™ï¸ **åŒ—äº¬ åŒ—äº¬å¸‚** æœªæ¥3å¤©å¤©æ°”é¢„æŠ¥

ğŸ“… **å‘å¸ƒæ—¶é—´**: 2025-11-11 18:07:39

ğŸ“… **2025-11-11** (2)
ğŸŒ¤ï¸ **å¤©æ°”**: ç™½å¤©æ™´ï¼Œå¤œé—´å¤šäº‘
ğŸŒ¡ï¸ **æ¸©åº¦**: ç™½å¤©14Â°Cï¼Œå¤œé—´3Â°C
ğŸ’¨ **é£åŠ›**: ç™½å¤©ä¸œåŒ—1-3ï¼Œå¤œé—´ä¸œåŒ—1-3

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
......
```

### ç¬¬å››éƒ¨åˆ†ï¼šæ–‡æ¡£å¤„ç†å™¨æ ¸å¿ƒåŠŸèƒ½ï¼ˆdocument_processor.py 1-174è¡Œï¼‰

**ä»£ç æ–‡ä»¶ï¼š** `03-smart-qa-application/utils/document_processor.py`

è¿™éƒ¨åˆ†å®ç°æ–‡æ¡£ä¸Šä¼ ã€ç¼“å­˜ã€å¤šæ ¼å¼åŠ è½½ã€‚

<details>
<summary>ç‚¹å‡»å±•å¼€ä»£ç ï¼ˆæ ¸å¿ƒæµç¨‹ï¼‰</summary>

```python
import os
import hashlib
import logging
from typing import List, Dict, Optional, Any
from pathlib import Path
import streamlit as st
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import PyPDFLoader, TextLoader, UnstructuredWordDocumentLoader
from config.settings import Settings

logger = logging.getLogger(__name__)

class DocumentProcessor:
    """æ–‡æ¡£å¤„ç†å™¨ç±»"""

    def __init__(self):
        self.settings = Settings()
        self.cache_dir = self.settings.DATA_DIR / "document_cache"
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def _get_file_hash(self, file_content: bytes) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        return hashlib.md5(file_content).hexdigest()

    def process_uploaded_file(self, uploaded_file) -> List[Document]:
        """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæ”¯æŒ UploadedFile å¯¹è±¡å’Œæ–‡ä»¶è·¯å¾„ï¼‰"""
        try:
            # å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥
            if hasattr(uploaded_file, 'size') and hasattr(uploaded_file, 'read'):
                # Streamlit UploadedFile å¯¹è±¡
                if uploaded_file.size > self.settings.MAX_FILE_SIZE:
                    raise ValueError(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {uploaded_file.size} > {self.settings.MAX_FILE_SIZE}")
                file_content = uploaded_file.read()
                file_name = uploaded_file.name
            else:
                # æ–‡ä»¶è·¯å¾„
                file_path = Path(uploaded_file)
                if not file_path.exists():
                    raise ValueError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                file_size = file_path.stat().st_size
                if file_size > self.settings.MAX_FILE_SIZE:
                    raise ValueError(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {file_size} > {self.settings.MAX_FILE_SIZE}")
                with open(file_path, 'rb') as f:
                    file_content = f.read()
                file_name = file_path.name
            
            file_type = Path(file_name).suffix.lower()

            # æ£€æŸ¥æ–‡ä»¶ç±»å‹
            if file_type not in self.settings.SUPPORTED_FILE_TYPES:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")

            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = self._get_file_hash(file_content)
            cache_path = self._get_cache_path(file_hash, file_name)

            # å°è¯•ä»ç¼“å­˜åŠ è½½
            cached_documents = self._load_from_cache(cache_path)
            if cached_documents is not None:
                return cached_documents

            # å¤„ç†æ–‡ä»¶
            documents = self._process_file_content(file_content, file_name, file_type)

            # ä¿å­˜åˆ°ç¼“å­˜
            self._save_to_cache(cache_path, documents)

            logger.info(f"å¤„ç†æ–‡ä»¶æˆåŠŸ: {file_name}, æ–‡æ¡£æ•°é‡: {len(documents)}")
            return documents

        except Exception as e:
            logger.error(f"å¤„ç†ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise

    def _process_file_content(self, file_content: bytes, file_name: str, file_type: str) -> List[Document]:
        """å¤„ç†æ–‡ä»¶å†…å®¹"""
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_dir = self.settings.DATA_DIR / "temp"
            temp_dir.mkdir(parents=True, exist_ok=True)
            temp_path = temp_dir / file_name

            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with open(temp_path, 'wb') as f:
                f.write(file_content)

            try:
                # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åŠ è½½å™¨
                if file_type == '.pdf':
                    documents = self._load_pdf(temp_path)
                elif file_type == '.txt':
                    documents = self._load_text(temp_path)
                elif file_type == '.md':
                    documents = self._load_markdown(temp_path)
                elif file_type == '.docx':
                    documents = self._load_word(temp_path)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")

                # æ·»åŠ å…ƒæ•°æ®
                for i, doc in enumerate(documents):
                    doc.metadata.update({
                        'source': file_name,
                        'file_type': file_type,
                        'chunk_index': i,
                        'total_chunks': len(documents),
                        'processing_timestamp': str(Path(temp_path).stat().st_mtime)
                    })

                return documents

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_path.exists():
                    temp_path.unlink()

        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å†…å®¹å¤±è´¥: {str(e)}")
            raise

    def _load_pdf(self, file_path: Path) -> List[Document]:
        """åŠ è½½PDFæ–‡ä»¶"""
        try:
            loader = PyPDFLoader(str(file_path))
            documents = loader.load()

            # æ·»åŠ é¡µç ä¿¡æ¯
            for i, doc in enumerate(documents):
                if 'page' not in doc.metadata:
                    doc.metadata['page'] = i + 1

            logger.info(f"åŠ è½½PDFæˆåŠŸ: {file_path.name}, é¡µæ•°: {len(documents)}")
            return documents

        except Exception as e:
            logger.error(f"åŠ è½½PDFå¤±è´¥: {str(e)}")
            raise
            
     def _load_text(self, file_path: Path) -> List[Document]:
            """åŠ è½½æ–‡æœ¬æ–‡ä»¶"""
            try:
                loader = TextLoader(str(file_path), encoding='utf-8')
                documents = loader.load()

                logger.info(f"åŠ è½½æ–‡æœ¬æ–‡ä»¶æˆåŠŸ: {file_path.name}")
                return documents

            except Exception as e:
                logger.error(f"åŠ è½½æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {str(e)}")
                raise
    
    def _load_markdown(self, file_path: Path) -> List[Document]:
        """åŠ è½½Markdownæ–‡ä»¶"""
        try:
            # Markdownæ–‡ä»¶ä¹Ÿä½¿ç”¨æ–‡æœ¬åŠ è½½å™¨
            loader = TextLoader(str(file_path), encoding='utf-8')
            documents = loader.load()
            
            # æ·»åŠ æ–‡ä»¶ç±»å‹æ ‡è¯†
            for doc in documents:
                doc.metadata['file_type'] = '.md'
            
            logger.info(f"åŠ è½½Markdownæ–‡ä»¶æˆåŠŸ: {file_path.name}")
            return documents
            
        except Exception as e:
            logger.error(f"åŠ è½½Markdownæ–‡ä»¶å¤±è´¥: {str(e)}")
            raise
    
    def _load_word(self, file_path: Path) -> List[Document]:
        """åŠ è½½Wordæ–‡æ¡£"""
        try:
            loader = UnstructuredWordDocumentLoader(str(file_path))
            documents = loader.load()
            
            logger.info(f"åŠ è½½Wordæ–‡æ¡£æˆåŠŸ: {file_path.name}")
            return documents
            
        except Exception as e:
            logger.error(f"åŠ è½½Wordæ–‡æ¡£å¤±è´¥: {str(e)}")
            raise           
```

</details>

**ä¸ºä»€ä¹ˆè¿™ä¹ˆå†™ï¼Ÿ**

1. **ä¸ºä»€ä¹ˆç”¨MD5å“ˆå¸Œï¼Ÿ**
   ```python
   file_hash = hashlib.md5(file_content).hexdigest()
   ```
   - **å»é‡**ï¼šç›¸åŒæ–‡ä»¶ä¸é‡å¤å¤„ç†
   - **ç¼“å­˜é”®**ï¼šå“ˆå¸Œå€¼ä½œä¸ºç¼“å­˜æ–‡ä»¶å
   - **å¿«é€Ÿè®¡ç®—**ï¼šMD5æ€§èƒ½å¥½ï¼ˆå®‰å…¨æ€§è¦æ±‚ä¸é«˜ï¼‰

2. **ä¸ºä»€ä¹ˆå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼Ÿ**
   ```python
   temp_path = temp_dir / file_name
   with open(temp_path, 'wb') as f:
       f.write(file_content)

   # ä½¿ç”¨LangChainåŠ è½½å™¨
   loader = PyPDFLoader(str(temp_path))
   ```
   - **Streamlitçš„é™åˆ¶**ï¼š`uploaded_file`æ˜¯å­—èŠ‚æµï¼Œä¸æ˜¯æ–‡ä»¶è·¯å¾„
   - **LangChainçš„è¦æ±‚**ï¼š`PyPDFLoader`éœ€è¦æ–‡ä»¶è·¯å¾„
   - **ä¸´æ—¶æ–‡ä»¶æ¡¥æ¥**ï¼šå­—èŠ‚æµ â†’ ä¸´æ—¶æ–‡ä»¶ â†’ åŠ è½½å™¨

3. **ä¸ºä»€ä¹ˆç”¨`finally`æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Ÿ**
   ```python
   try:
       documents = self._load_pdf(temp_path)
   finally:
       if temp_path.exists():
           temp_path.unlink()  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
   ```
   - æ— è®ºæˆåŠŸæˆ–å¤±è´¥ï¼Œéƒ½è¦æ¸…ç†
   - é¿å…ä¸´æ—¶æ–‡ä»¶ç´¯ç§¯å ç”¨ç£ç›˜
   - `finally`ç¡®ä¿ä¸€å®šæ‰§è¡Œ

4. **ä¸ºä»€ä¹ˆæ·»åŠ å…ƒæ•°æ®ï¼Ÿ**
   ```python
   doc.metadata.update({
       'source': file_name,
       'file_type': file_type,
       'chunk_index': i,
       'total_chunks': len(documents)
   })
   ```
   - **è¿½æº¯æ€§**ï¼šçŸ¥é“ç­”æ¡ˆæ¥è‡ªå“ªä¸ªæ–‡ä»¶
   - **è°ƒè¯•**ï¼šå®šä½é—®é¢˜æ–‡æ¡£
   - **å±•ç¤º**ï¼šåœ¨UIä¸­æ˜¾ç¤ºæ¥æº

### ç¬¬äº”éƒ¨åˆ†ï¼šåˆ†å‰²æ–‡æ¡£æ ¸å¿ƒåŠŸèƒ½ï¼ˆdocument_processor.py 237-265è¡Œï¼‰

**ä»£ç æ–‡ä»¶ï¼š** `03-smart-qa-application/utils/document_processor.py`

```python
    def split_documents(self, documents: List[Document], chunk_size: int = None, chunk_overlap: int = None) -> List[Document]:
        """åˆ†å‰²æ–‡æ¡£"""
        try:
            chunk_size = chunk_size or self.settings.CHUNK_SIZE
            chunk_overlap = chunk_overlap or self.settings.CHUNK_OVERLAP
            
            logger.info(f"åˆ†å‰²æ–‡æ¡£ï¼Œchunk_size: {chunk_size}, chunk_overlap: {chunk_overlap}")
            
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                length_function=len,
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", " ", ""]
            )
            
            split_docs = text_splitter.split_documents(documents)
            
            # æ›´æ–°å…ƒæ•°æ®
            for i, doc in enumerate(split_docs):
                doc.metadata['chunk_index'] = i
                doc.metadata['chunk_size'] = len(doc.page_content)
                doc.metadata['total_chunks'] = len(split_docs)
            
            logger.info(f"æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œç‰‡æ®µæ•°é‡: {len(split_docs)}")
            return split_docs
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£åˆ†å‰²å¤±è´¥: {str(e)}")
            return documents
```

ä»¥ä¸Šä»£ç è§£é‡Šï¼š

> ## ğŸ“‹ **ä»£ç è§£é‡Šï¼š`split_documents`æ–¹æ³•**
>
> è¿™æ®µä»£ç çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯**æ™ºèƒ½åˆ†å‰²æ–‡æ¡£**ï¼Œè®©æˆ‘è¯¦ç»†è§£é‡Šæ¯ä¸ªéƒ¨åˆ†ï¼š
>
> ### ğŸ¯ **æ–¹æ³•ä½œç”¨**
> ```python
> def split_documents(self, documents: List[Document], chunk_size: int = None, chunk_overlap: int = None) -> List[Document]:
> ```
> - **è¾“å…¥**ï¼šDocumentå¯¹è±¡åˆ—è¡¨
> - **è¾“å‡º**ï¼šåˆ†å‰²åçš„Documentå¯¹è±¡åˆ—è¡¨
> - **ç›®çš„**ï¼šå°†é•¿æ–‡æ¡£åˆ†å‰²æˆåˆé€‚å¤§å°çš„ç‰‡æ®µï¼Œä¾¿äºåç»­å¤„ç†
>
> ---
>
> ### âš™ï¸ **å‚æ•°é…ç½®**
> ```python
> chunk_size = chunk_size or self.settings.CHUNK_SIZE
> chunk_overlap = chunk_overlap or self.settings.CHUNK_OVERLAP
> ```
> - **chunk_size**ï¼šæ¯ä¸ªç‰‡æ®µçš„æœ€å¤§å­—ç¬¦æ•°ï¼ˆé»˜è®¤1000ï¼‰
> - **chunk_overlap**ï¼šç›¸é‚»ç‰‡æ®µçš„é‡å å­—ç¬¦æ•°ï¼ˆé»˜è®¤200ï¼‰
> - **ä½œç”¨**ï¼šé¿å…åœ¨é‡è¦ä½ç½®åˆ‡æ–­å†…å®¹
>
> ---
>
> ### ğŸ”§ **åˆ†å‰²å™¨é…ç½®**
> ```python
> text_splitter = RecursiveCharacterTextSplitter(
>     chunk_size=chunk_size,
>     chunk_overlap=chunk_overlap,
>     length_function=len,
>     separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", " ", ""]
> )
> ```
> - **æ™ºèƒ½åˆ†å‰²**ï¼šæŒ‰ä¼˜å…ˆçº§å¯»æ‰¾åˆ†å‰²ç‚¹
> - **åˆ†å‰²é¡ºåº**ï¼š
>   1. åŒæ¢è¡Œç¬¦ï¼ˆæ®µè½ï¼‰
>   2. å•æ¢è¡Œç¬¦ï¼ˆè¡Œï¼‰
>   3. ä¸­æ–‡å¥å·
>   4. ä¸­æ–‡æ„Ÿå¹å·
>   5. ä¸­æ–‡é—®å·
>   6. ä¸­æ–‡é€—å·
>   7. ç©ºæ ¼
>   8. ä»»æ„å­—ç¬¦ï¼ˆæœ€åæ‰‹æ®µï¼‰
>
> ---
>
> ### ğŸ“Š **å…ƒæ•°æ®æ›´æ–°**
> ```python
> for i, doc in enumerate(split_docs):
>     doc.metadata['chunk_index'] = i
>     doc.metadata['chunk_size'] = len(doc.page_content)
>     doc.metadata['total_chunks'] = len(split_docs)
> ```
> - **chunk_index**ï¼šç‰‡æ®µåºå·
> - **chunk_size**ï¼šç‰‡æ®µå®é™…å¤§å°
> - **total_chunks**ï¼šæ€»ç‰‡æ®µæ•°
>
> ---
>
> ### ğŸ’¡ **å®é™…åº”ç”¨åœºæ™¯**
>
> **åŸå§‹æ–‡æ¡£ï¼š**
> ```
> äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚è¯¥é¢†åŸŸçš„ç ”ç©¶åŒ…æ‹¬æœºå™¨äººã€è¯­è¨€è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¸“å®¶ç³»ç»Ÿç­‰ã€‚
> 
> äººå·¥æ™ºèƒ½ä»è¯ç”Ÿä»¥æ¥ï¼Œç†è®ºå’ŒæŠ€æœ¯æ—¥ç›Šæˆç†Ÿï¼Œåº”ç”¨é¢†åŸŸä¹Ÿä¸æ–­æ‰©å¤§ã€‚å¯ä»¥è®¾æƒ³ï¼Œæœªæ¥äººå·¥æ™ºèƒ½å¸¦æ¥çš„ç§‘æŠ€äº§å“ï¼Œå°†ä¼šæ˜¯äººç±»æ™ºæ…§çš„â€œå®¹å™¨â€ã€‚äººå·¥æ™ºèƒ½å¯ä»¥å¯¹äººçš„æ„è¯†ã€æ€ç»´çš„ä¿¡æ¯è¿‡ç¨‹çš„æ¨¡æ‹Ÿã€‚äººå·¥æ™ºèƒ½ä¸æ˜¯äººçš„æ™ºèƒ½ï¼Œä½†èƒ½åƒäººé‚£æ ·æ€è€ƒã€ä¹Ÿå¯èƒ½è¶…è¿‡äººçš„æ™ºèƒ½ã€‚
> ```
>
> **åˆ†å‰²ç»“æœï¼š**
> - **ç‰‡æ®µ1**ï¼šäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯...ï¼ˆçº¦1000å­—ç¬¦ï¼‰
> - **ç‰‡æ®µ2**ï¼šäººå·¥æ™ºèƒ½ä»è¯ç”Ÿä»¥æ¥ï¼Œç†è®ºå’ŒæŠ€æœ¯æ—¥ç›Šæˆç†Ÿ...ï¼ˆçº¦1000å­—ç¬¦ï¼‰
>
> ---
>
> ### ğŸ›¡ï¸ **é”™è¯¯å¤„ç†**
> ```python
> except Exception as e:
>     logger.error(f"æ–‡æ¡£åˆ†å‰²å¤±è´¥: {str(e)}")
>     return documents
> ```
> - **å®¹é”™æœºåˆ¶**ï¼šåˆ†å‰²å¤±è´¥æ—¶è¿”å›åŸæ–‡æ¡£
> - **æ—¥å¿—è®°å½•**ï¼šè®°å½•é”™è¯¯ä¿¡æ¯ä¾¿äºè°ƒè¯•
>
> ---
>
> ### ğŸ¨ **è®¾è®¡ä¼˜åŠ¿**
>
> 1. **æ™ºèƒ½åˆ†å‰²**ï¼šä¼˜å…ˆåœ¨è¯­ä¹‰å®Œæ•´å¤„åˆ†å‰²
> 2. **ä¸Šä¸‹æ–‡ä¿ç•™**ï¼šé‡å è®¾è®¡ä¿æŒè¯­ä¹‰è¿è´¯æ€§
> 3. **å¯è¿½æº¯æ€§**ï¼šå…ƒæ•°æ®è®°å½•åˆ†å‰²ä¿¡æ¯
> 4. **å¤šè¯­è¨€æ”¯æŒ**ï¼šæ”¯æŒä¸­è‹±æ–‡åˆ†å‰²ç¬¦
> 5. **å®¹é”™å¤„ç†**ï¼šå¤±è´¥æ—¶ä¼˜é›…é™çº§
>
> è¿™ä¸ªåˆ†å‰²ç­–ç•¥ç‰¹åˆ«é€‚åˆRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰åº”ç”¨ï¼Œèƒ½ç¡®ä¿æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µæ—¢å®Œæ•´åˆæœ‰æ„ä¹‰ï¼

### ç¬¬å…­éƒ¨åˆ†ï¼šæ–‡æ¡£ç¼“å­˜ç®¡ç†æœºåˆ¶ï¼ˆdocument_processor.pyï¼‰

**ä»£ç æ–‡ä»¶ï¼š** `03-smart-qa-application/utils/document_processor.py`

è¿™éƒ¨åˆ†å®ç°äº†æ–‡æ¡£çš„ç¼“å­˜æœºåˆ¶ã€‚

<details>
<parameter name="content">
<summary>ç‚¹å‡»å±•å¼€ä»£ç ï¼ˆç¼“å­˜æ ¸å¿ƒï¼‰</summary>

```python
    def _get_cache_path(self, file_hash: str, file_name: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{file_hash}_{file_name}.json"
    
    def _load_from_cache(self, cache_path: Path) -> Optional[List[Document]]:
        """ä»ç¼“å­˜åŠ è½½æ–‡æ¡£"""
        try:
            if cache_path.exists() and self.settings.CACHE_ENABLED:
                import json
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    
                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                import time
                current_time = time.time()
                cache_time = cache_data.get('timestamp', 0)
                
                if current_time - cache_time < self.settings.CACHE_EXPIRE_TIME:
                    # é‡å»ºDocumentå¯¹è±¡
                    documents = []
                    for doc_data in cache_data.get('documents', []):
                        doc = Document(
                            page_content=doc_data['page_content'],
                            metadata=doc_data['metadata']
                        )
                        documents.append(doc)
                    
                    logger.info(f"ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: {len(documents)} ä¸ªæ–‡æ¡£")
                    return documents
                else:
                    logger.info("ç¼“å­˜å·²è¿‡æœŸ")
                    
        except Exception as e:
            logger.error(f"ä»ç¼“å­˜åŠ è½½å¤±è´¥: {str(e)}")
        
        return None
    
    def _save_to_cache(self, cache_path: Path, documents: List[Document]):
        """ä¿å­˜æ–‡æ¡£åˆ°ç¼“å­˜"""
        try:
            if not self.settings.CACHE_ENABLED:
                return
                
            import json
            import time
            
            cache_data = {
                'timestamp': time.time(),
                'documents': [
                    {
                        'page_content': doc.page_content,
                        'metadata': doc.metadata
                    }
                    for doc in documents
                ]
            }
            
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ä¿å­˜åˆ°ç¼“å­˜æˆåŠŸ: {cache_path}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ°ç¼“å­˜å¤±è´¥: {str(e)}")
            
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            cache_files = list(self.cache_dir.glob("*.json"))
            total_size = sum(f.stat().st_size for f in cache_files)
            
            stats = {
                'cache_enabled': self.settings.CACHE_ENABLED,
                'cache_expire_time': self.settings.CACHE_EXPIRE_TIME,
                'cache_files_count': len(cache_files),
                'cache_total_size_bytes': total_size,
                'cache_total_size_mb': round(total_size / (1024 * 1024), 2)
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {'error': str(e)}
    
    def clear_cache(self) -> bool:
        """æ¸…ç©ºç¼“å­˜"""
        try:
            cache_files = list(self.cache_dir.glob("*.json"))
            deleted_count = 0
            
            for cache_file in cache_files:
                try:
                    cache_file.unlink()
                    deleted_count += 1
                except Exception as e:
                    logger.error(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {cache_file}, é”™è¯¯: {str(e)}")
            
            logger.info(f"æ¸…ç©ºç¼“å­˜æˆåŠŸï¼Œåˆ é™¤æ–‡ä»¶æ•°: {deleted_count}")
            return True
            
        except Exception as e:
            logger.error(f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {str(e)}")
            return False            
```

</details>

**ä»£ç è§£é‡Šï¼š**

>
> æˆ‘æ¥è¯¦ç»†è§£é‡Šè¿™æ®µç¼“å­˜å¤„ç†ä»£ç çš„åŠŸèƒ½å’Œä½¿ç”¨æ–¹æ³•ã€‚
>
> ## ğŸ“‹ **ç¼“å­˜å¤„ç†ä»£ç åŠŸèƒ½æ¦‚è¿°**
>
> è¿™æ®µä»£ç å®ç°äº†æ–‡æ¡£å¤„ç†çš„æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š
>
> ### ğŸ”§ **æ ¸å¿ƒæ–¹æ³•è¯´æ˜**
>
> #### 1ï¸âƒ£ **ç¼“å­˜è·¯å¾„ç”Ÿæˆ** (`_get_cache_path`)
> ```python
> def _get_cache_path(self, file_hash: str, file_name: str) -> Path:
>     """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
>     return self.cache_dir / f"{file_hash}_{file_name}.json"
> ```
> - **ä½œç”¨**ï¼šæ ¹æ®æ–‡ä»¶å“ˆå¸Œå’Œæ–‡ä»¶åç”Ÿæˆå”¯ä¸€çš„ç¼“å­˜æ–‡ä»¶è·¯å¾„
> - **æ ¼å¼**ï¼š`{æ–‡ä»¶å“ˆå¸Œ}_{æ–‡ä»¶å}.json`
>
> #### 2ï¸âƒ£ **ä»ç¼“å­˜åŠ è½½** (`_load_from_cache`)
> ```python
> def _load_from_cache(self, cache_path: Path) -> Optional[List[Document]]:
>     """ä»ç¼“å­˜åŠ è½½æ–‡æ¡£"""
> ```
> - **åŠŸèƒ½**ï¼šæ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸï¼Œé‡å»ºDocumentå¯¹è±¡
> - **è¿‡æœŸæ£€æŸ¥**ï¼šæ¯”è¾ƒå½“å‰æ—¶é—´ä¸ç¼“å­˜æ—¶é—´æˆ³
> - **è¿”å›å€¼**ï¼šæ–‡æ¡£åˆ—è¡¨æˆ–None
>
> #### 3ï¸âƒ£ **ä¿å­˜åˆ°ç¼“å­˜** (`_save_to_cache`)
> ```python
> def _save_to_cache(self, cache_path: Path, documents: List[Document]):
>     """ä¿å­˜æ–‡æ¡£åˆ°ç¼“å­˜"""
> ```
> - **åŠŸèƒ½**ï¼šå°†å¤„ç†åçš„æ–‡æ¡£åºåˆ—åŒ–ä¿å­˜åˆ°JSONæ–‡ä»¶
> - **åŒ…å«ä¿¡æ¯**ï¼šæ—¶é—´æˆ³ã€æ–‡æ¡£å†…å®¹ã€å…ƒæ•°æ®
>
> #### 4ï¸âƒ£ **ç¼“å­˜ç»Ÿè®¡** (`get_cache_stats`)
> ```python
> def get_cache_stats(self) -> Dict[str, Any]:
>     """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
> ```
> - **è¿”å›**ï¼šç¼“å­˜æ–‡ä»¶æ•°é‡ã€æ€»å¤§å°ã€çŠ¶æ€ç­‰ä¿¡æ¯
>
> #### 5ï¸âƒ£ **æ¸…ç©ºç¼“å­˜** (`clear_cache`)
> ```python
> def clear_cache(self) -> bool:
>     """æ¸…ç©ºç¼“å­˜"""
> ```
> - **åŠŸèƒ½**ï¼šåˆ é™¤æ‰€æœ‰ç¼“å­˜æ–‡ä»¶
> - **æ³¨æ„**ï¼šä»£ç æœ«å°¾æœ‰è¯­æ³•é”™è¯¯ `return false` åº”ä¸º `return False`
>
> ## ğŸ’» **ä½¿ç”¨ç¤ºä¾‹**
>
> ### ğŸ“– **åŸºæœ¬ä½¿ç”¨æµç¨‹**
>
> ```python
> from utils.document_processor import DocumentProcessor
> from config.settings import Settings
> 
> # åˆå§‹åŒ–å¤„ç†å™¨
> settings = Settings()
> processor = DocumentProcessor(settings)
> 
> # 1. å¤„ç†æ–‡æ¡£ï¼ˆä¼šè‡ªåŠ¨æ£€æŸ¥ç¼“å­˜ï¼‰
> documents = processor.process_uploaded_file("example.pdf")
> 
> # 2. æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
> stats = processor.get_cache_stats()
> print(f"ç¼“å­˜æ–‡ä»¶æ•°: {stats['cache_files_count']}")
> print(f"ç¼“å­˜å¤§å°: {stats['cache_total_size_mb']} MB")
> 
> # 3. æ¸…ç©ºç¼“å­˜
> success = processor.clear_cache()
> print(f"æ¸…ç©ºç¼“å­˜: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
> ```
>
> ### ğŸ”„ **ç¼“å­˜å·¥ä½œæµç¨‹ç¤ºä¾‹**
>
> ```python
> import hashlib
> import time
> 
> # æ¨¡æ‹Ÿæ–‡ä»¶å¤„ç†æµç¨‹
> def process_with_cache_example():
>     # ç¬¬ä¸€æ¬¡å¤„ç†ï¼šæ²¡æœ‰ç¼“å­˜ï¼Œéœ€è¦å®é™…å¤„ç†
>     print("=== ç¬¬ä¸€æ¬¡å¤„ç† ===")
>     docs1 = processor.process_uploaded_file("test.pdf")
>     
>     # ç«‹å³å†æ¬¡å¤„ç†ï¼šåº”è¯¥å‘½ä¸­ç¼“å­˜
>     print("=== ç¬¬äºŒæ¬¡å¤„ç†ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰==="")
>     docs2 = processor.process_uploaded_file("test.pdf")
>     
>     # ä¿®æ”¹æ–‡ä»¶åå¤„ç†ï¼šç¼“å­˜å¤±æ•ˆ
>     print("=== æ–‡ä»¶ä¿®æ”¹åå¤„ç† ===")
>     # è¿™é‡Œæ¨¡æ‹Ÿæ–‡ä»¶å†…å®¹å˜åŒ–
>     docs3 = processor.process_uploaded_file("modified_test.pdf")
> ```
>
> ### ğŸ“Š **ç¼“å­˜å‘½ä¸­æ£€æŸ¥**
>
> ```python
> def check_cache_performance():
>     """æ£€æŸ¥ç¼“å­˜æ€§èƒ½"""
>     import time
>     
>     # æµ‹è¯•æœ‰ç¼“å­˜å’Œæ— ç¼“å­˜çš„å¤„ç†æ—¶é—´
>     files = ["doc1.pdf", "doc2.txt", "doc3.md"]
>     
>     for file_path in files:
>         # ç¬¬ä¸€æ¬¡å¤„ç†ï¼ˆæ— ç¼“å­˜ï¼‰
>         start = time.time()
>         docs1 = processor.process_uploaded_file(file_path)
>         time1 = time.time() - start
>         
>         # ç¬¬äºŒæ¬¡å¤„ç†ï¼ˆæœ‰ç¼“å­˜ï¼‰
>         start = time.time()
>         docs2 = processor.process_uploaded_file(file_path)
>         time2 = time.time() - start
>         
>         print(f"æ–‡ä»¶: {file_path}")
>         print(f"  é¦–æ¬¡å¤„ç†: {time1:.3f}ç§’")
>         print(f"  ç¼“å­˜å¤„ç†: {time2:.3f}ç§’")
>         print(f"  åŠ é€Ÿæ¯”: {time1/time2:.1f}x")
> ```
>
> ## âš™ï¸ **é…ç½®è¯´æ˜**
>
> ç¼“å­˜è¡Œä¸ºç”±è®¾ç½®æ§åˆ¶ï¼š
>
> ```python
> # åœ¨ config/settings.py ä¸­
> CACHE_ENABLED = True          # å¯ç”¨ç¼“å­˜
> CACHE_EXPIRE_TIME = 3600      # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
> CACHE_DIR = "cache"           # ç¼“å­˜ç›®å½•
> ```
>
> ## ğŸ¯ **ç¼“å­˜ä¼˜åŠ¿**
>
> 1. **ğŸš€ æ€§èƒ½æå‡**ï¼šé¿å…é‡å¤å¤„ç†ç›¸åŒæ–‡ä»¶
> 2. **ğŸ’¾ èŠ‚çœèµ„æº**ï¼šå‡å°‘CPUå’Œå†…å­˜æ¶ˆè€—
> 3. **âš¡ å¿«é€Ÿå“åº”**ï¼šç¼“å­˜å‘½ä¸­æ—¶ç«‹å³è¿”å›ç»“æœ
> 4. **ğŸ”„ æ™ºèƒ½å¤±æ•ˆ**ï¼šæ–‡ä»¶å˜åŒ–æ—¶è‡ªåŠ¨é‡æ–°å¤„ç†    
>

### ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæ–‡æ¡£çš„æ‰¹é‡å¤„ç†ï¼ˆdocument_processor.pyï¼‰

**ä»£ç æ–‡ä»¶ï¼š** `03-smart-qa-application/utils/document_processor.py`

```python
    def process_documents_batch(self, uploaded_files: List) -> Dict[str, Any]:
        """æ‰¹é‡å¤„ç†æ–‡æ¡£"""
        try:
            results = {
                'total_files': len(uploaded_files),
                'processed_files': 0,
                'failed_files': 0,
                'total_documents': 0,
                'errors': []
            }
            
            all_documents = []
            
            for file in uploaded_files:
                try:
                    documents = self.process_uploaded_file(file)
                    all_documents.extend(documents)
                    results['processed_files'] += 1
                    results['total_documents'] += len(documents)
                    
                    logger.info(f"å¤„ç†æ–‡ä»¶æˆåŠŸ: {file.name}")
                    
                except Exception as e:
                    results['failed_files'] += 1
                    error_info = {
                        'file_name': file.name,
                        'error': str(e)
                    }
                    results['errors'].append(error_info)
                    logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {file.name}, é”™è¯¯: {str(e)}")
            
            results['all_documents'] = all_documents
            return results
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†æ–‡æ¡£å¤±è´¥: {str(e)}")
            raise
```

**ä»£ç è¯´æ˜ï¼š**

> æ–¹æ³•å®ç°äº† æ‰¹é‡æ–‡æ¡£å¤„ç† åŠŸèƒ½ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†å¤šä¸ªä¸Šä¼ çš„æ–‡ä»¶ï¼Œå¹¶æä¾›è¯¦ç»†çš„å¤„ç†ç»Ÿè®¡ä¿¡æ¯ã€‚
>
> ### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
>
> 1. ğŸ“Š æ‰¹é‡ç»Ÿè®¡ ï¼šè·Ÿè¸ªæ€»æ–‡ä»¶æ•°ã€æˆåŠŸ/å¤±è´¥æ–‡ä»¶æ•°ã€æ–‡æ¡£æ€»æ•°
> 2. ğŸ”„ é€ä¸ªå¤„ç† ï¼šå¾ªç¯å¤„ç†æ¯ä¸ªæ–‡ä»¶ï¼Œæ”¯æŒä¸åŒæ–‡ä»¶ç±»å‹
> 3. âš ï¸ é”™è¯¯éš”ç¦» ï¼šå•ä¸ªæ–‡ä»¶å¤±è´¥ä¸å½±å“å…¶ä»–æ–‡ä»¶å¤„ç†
> 4. ğŸ“ è¯¦ç»†æ—¥å¿— ï¼šè®°å½•æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†çŠ¶æ€å’Œé”™è¯¯ä¿¡æ¯
> 5. ğŸ“¦ ç»“æœèšåˆ ï¼šè¿”å›æ‰€æœ‰æ–‡æ¡£çš„é›†åˆ
>
> Trae
>
> å‚è€ƒäº† 2 ä¸ªä¸Šä¸‹æ–‡
>
> æˆ‘æ¥è¯¦ç»†è§£é‡Šè¿™æ®µç¼“å­˜å¤„ç†ä»£ç çš„åŠŸèƒ½å’Œä½¿ç”¨æ–¹æ³•ã€‚
>
> ## ğŸ“‹ ç¼“å­˜å¤„ç†ä»£ç åŠŸèƒ½æ¦‚è¿°
> è¿™æ®µä»£ç å®ç°äº†æ–‡æ¡£å¤„ç†çš„æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š
>
> ### ğŸ”§ æ ¸å¿ƒæ–¹æ³•è¯´æ˜ 1ï¸âƒ£ ç¼“å­˜è·¯å¾„ç”Ÿæˆ ( _get_cache_path )
> ```
> def _get_cache_path(self, file_hash: str, file_name: str) -> Path:
>     """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
>     return self.cache_dir / f"{file_hash}_{file_name}.json"
> ```
> - ä½œç”¨ ï¼šæ ¹æ®æ–‡ä»¶å“ˆå¸Œå’Œæ–‡ä»¶åç”Ÿæˆå”¯ä¸€çš„ç¼“å­˜æ–‡ä»¶è·¯å¾„
> - æ ¼å¼ ï¼š {æ–‡ä»¶å“ˆå¸Œ}_{æ–‡ä»¶å}.json 2ï¸âƒ£ ä»ç¼“å­˜åŠ è½½ ( _load_from_cache )
> ```
> def _load_from_cache(self, cache_path: Path) -> Optional[List
> [Document]]:
>     """ä»ç¼“å­˜åŠ è½½æ–‡æ¡£"""
> ```
> - åŠŸèƒ½ ï¼šæ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸï¼Œé‡å»ºDocumentå¯¹è±¡
> - è¿‡æœŸæ£€æŸ¥ ï¼šæ¯”è¾ƒå½“å‰æ—¶é—´ä¸ç¼“å­˜æ—¶é—´æˆ³
> - è¿”å›å€¼ ï¼šæ–‡æ¡£åˆ—è¡¨æˆ–None 3ï¸âƒ£ ä¿å­˜åˆ°ç¼“å­˜ ( _save_to_cache )
> ```
> def _save_to_cache(self, cache_path: Path, documents: List
> [Document]):
>     """ä¿å­˜æ–‡æ¡£åˆ°ç¼“å­˜"""
> ```
> - åŠŸèƒ½ ï¼šå°†å¤„ç†åçš„æ–‡æ¡£åºåˆ—åŒ–ä¿å­˜åˆ°JSONæ–‡ä»¶
> - åŒ…å«ä¿¡æ¯ ï¼šæ—¶é—´æˆ³ã€æ–‡æ¡£å†…å®¹ã€å…ƒæ•°æ® 4ï¸âƒ£ ç¼“å­˜ç»Ÿè®¡ ( get_cache_stats )
> ```
> def get_cache_stats(self) -> Dict[str, Any]:
>     """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
> ```
> - è¿”å› ï¼šç¼“å­˜æ–‡ä»¶æ•°é‡ã€æ€»å¤§å°ã€çŠ¶æ€ç­‰ä¿¡æ¯ 5ï¸âƒ£ æ¸…ç©ºç¼“å­˜ ( clear_cache )
> ```
> def clear_cache(self) -> bool:
>     """æ¸…ç©ºç¼“å­˜"""
> ```
> - åŠŸèƒ½ ï¼šåˆ é™¤æ‰€æœ‰ç¼“å­˜æ–‡ä»¶
> - æ³¨æ„ ï¼šä»£ç æœ«å°¾æœ‰è¯­æ³•é”™è¯¯ return false åº”ä¸º return False
> ## ğŸ’» ä½¿ç”¨ç¤ºä¾‹
> ### ğŸ“– åŸºæœ¬ä½¿ç”¨æµç¨‹
> ```
> from utils.document_processor import DocumentProcessor
> from config.settings import Settings
> 
> # åˆå§‹åŒ–å¤„ç†å™¨
> settings = Settings()
> processor = DocumentProcessor(settings)
> 
> # 1. å¤„ç†æ–‡æ¡£ï¼ˆä¼šè‡ªåŠ¨æ£€æŸ¥ç¼“å­˜ï¼‰
> documents = processor.process_uploaded_file("example.pdf")
> 
> # 2. æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
> stats = processor.get_cache_stats()
> print(f"ç¼“å­˜æ–‡ä»¶æ•°: {stats['cache_files_count']}")
> print(f"ç¼“å­˜å¤§å°: {stats['cache_total_size_mb']} MB")
> 
> # 3. æ¸…ç©ºç¼“å­˜
> success = processor.clear_cache()
> print(f"æ¸…ç©ºç¼“å­˜: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
> ```
> ### ğŸ”„ ç¼“å­˜å·¥ä½œæµç¨‹ç¤ºä¾‹
> ```
> import hashlib
> import time
> 
> # æ¨¡æ‹Ÿæ–‡ä»¶å¤„ç†æµç¨‹
> def process_with_cache_example():
>     # ç¬¬ä¸€æ¬¡å¤„ç†ï¼šæ²¡æœ‰ç¼“å­˜ï¼Œéœ€è¦å®é™…å¤„ç†
>     print("=== ç¬¬ä¸€æ¬¡å¤„ç† ===")
>     docs1 = processor.process_uploaded_file("test.pdf")
>     
>     # ç«‹å³å†æ¬¡å¤„ç†ï¼šåº”è¯¥å‘½ä¸­ç¼“å­˜
>     print("=== ç¬¬äºŒæ¬¡å¤„ç†ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰==="")
>     docs2 = processor.process_uploaded_file("test.pdf")
>     
>     # ä¿®æ”¹æ–‡ä»¶åå¤„ç†ï¼šç¼“å­˜å¤±æ•ˆ
>     print("=== æ–‡ä»¶ä¿®æ”¹åå¤„ç† ===")
>     # è¿™é‡Œæ¨¡æ‹Ÿæ–‡ä»¶å†…å®¹å˜åŒ–
>     docs3 = processor.process_uploaded_file("modified_test.pdf")
> ```
> ### ğŸ“Š ç¼“å­˜å‘½ä¸­æ£€æŸ¥
> ```
> def check_cache_performance():
>     """æ£€æŸ¥ç¼“å­˜æ€§èƒ½"""
>     import time
>     
>     # æµ‹è¯•æœ‰ç¼“å­˜å’Œæ— ç¼“å­˜çš„å¤„ç†æ—¶é—´
>     files = ["doc1.pdf", "doc2.txt", "doc3.md"]
>     
>     for file_path in files:
>         # ç¬¬ä¸€æ¬¡å¤„ç†ï¼ˆæ— ç¼“å­˜ï¼‰
>         start = time.time()
>         docs1 = processor.process_uploaded_file(file_path)
>         time1 = time.time() - start
>         
>         # ç¬¬äºŒæ¬¡å¤„ç†ï¼ˆæœ‰ç¼“å­˜ï¼‰
>         start = time.time()
>         docs2 = processor.process_uploaded_file(file_path)
>         time2 = time.time() - start
>         
>         print(f"æ–‡ä»¶: {file_path}")
>         print(f"  é¦–æ¬¡å¤„ç†: {time1:.3f}ç§’")
>         print(f"  ç¼“å­˜å¤„ç†: {time2:.3f}ç§’")
>         print(f"  åŠ é€Ÿæ¯”: {time1/time2:.1f}x")
> ```
> ## âš™ï¸ é…ç½®è¯´æ˜
> ç¼“å­˜è¡Œä¸ºç”±è®¾ç½®æ§åˆ¶ï¼š
>
> ```
> # åœ¨ config/settings.py ä¸­
> CACHE_ENABLED = True          # å¯ç”¨ç¼“å­˜
> CACHE_EXPIRE_TIME = 3600      # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
> CACHE_DIR = "cache"           # ç¼“å­˜ç›®å½•
> ```
> ## ğŸ¯ ç¼“å­˜ä¼˜åŠ¿
> 1. ğŸš€ æ€§èƒ½æå‡ ï¼šé¿å…é‡å¤å¤„ç†ç›¸åŒæ–‡ä»¶
> 2. ğŸ’¾ èŠ‚çœèµ„æº ï¼šå‡å°‘CPUå’Œå†…å­˜æ¶ˆè€—
> 3. âš¡ å¿«é€Ÿå“åº” ï¼šç¼“å­˜å‘½ä¸­æ—¶ç«‹å³è¿”å›ç»“æœ
> 4. ğŸ”„ æ™ºèƒ½å¤±æ•ˆ ï¼šæ–‡ä»¶å˜åŒ–æ—¶è‡ªåŠ¨é‡æ–°å¤„ç†
> ## âš ï¸ æ³¨æ„äº‹é¡¹
> 1. ğŸ”§ ä¿®å¤è¯­æ³•é”™è¯¯ ï¼šéœ€è¦å°† return false æ”¹ä¸º return False
> 2. ğŸ§¹ å®šæœŸæ¸…ç† ï¼šé•¿æ—¶é—´è¿è¡Œå¯èƒ½ç§¯ç´¯å¤§é‡ç¼“å­˜æ–‡ä»¶
> 3. ğŸ’½ ç£ç›˜ç©ºé—´ ï¼šç›‘æ§ç¼“å­˜å ç”¨çš„ç£ç›˜ç©ºé—´
> 4. ğŸ” æ–‡ä»¶å“ˆå¸Œ ï¼šç¡®ä¿æ–‡ä»¶å†…å®¹å˜åŒ–èƒ½æ­£ç¡®è¯†åˆ«
> è¿™æ®µç¼“å­˜ç³»ç»Ÿé€šè¿‡æ™ºèƒ½çš„æ–‡ä»¶å“ˆå¸Œå’Œè¿‡æœŸæœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†æ–‡æ¡£é‡å¤å¤„ç†çš„æ•ˆç‡ï¼
>
> ### ğŸ” æ–¹æ³•åŠŸèƒ½æ¦‚è¿°
>process_documents_batch æ–¹æ³•å®ç°äº† æ‰¹é‡æ–‡æ¡£å¤„ç† åŠŸèƒ½ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†å¤šä¸ªä¸Šä¼ çš„æ–‡ä»¶ï¼Œå¹¶æä¾›è¯¦ç»†çš„å¤„ç†ç»Ÿè®¡ä¿¡æ¯ã€‚
> 
>### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
> 1. ğŸ“Š æ‰¹é‡ç»Ÿè®¡ ï¼šè·Ÿè¸ªæ€»æ–‡ä»¶æ•°ã€æˆåŠŸ/å¤±è´¥æ–‡ä»¶æ•°ã€æ–‡æ¡£æ€»æ•°
>2. ğŸ”„ é€ä¸ªå¤„ç† ï¼šå¾ªç¯å¤„ç†æ¯ä¸ªæ–‡ä»¶ï¼Œæ”¯æŒä¸åŒæ–‡ä»¶ç±»å‹
> 3. âš ï¸ é”™è¯¯éš”ç¦» ï¼šå•ä¸ªæ–‡ä»¶å¤±è´¥ä¸å½±å“å…¶ä»–æ–‡ä»¶å¤„ç†
>4. ğŸ“ è¯¦ç»†æ—¥å¿— ï¼šè®°å½•æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†çŠ¶æ€å’Œé”™è¯¯ä¿¡æ¯
> 5. ğŸ“¦ ç»“æœèšåˆ ï¼šè¿”å›æ‰€æœ‰æ–‡æ¡£çš„é›†åˆ
>## ğŸ’» ä½¿ç”¨ç¤ºä¾‹
> ### ğŸ“– åŸºæœ¬æ‰¹é‡å¤„ç†
>
> ```python
>from utils.document_processor import DocumentProcessor
> from config.settings import Settings
> import streamlit as st
> 
># åˆå§‹åŒ–å¤„ç†å™¨
> settings = Settings()
> processor = DocumentProcessor(settings)
> 
> # Streamlit æ–‡ä»¶ä¸Šä¼ ç¤ºä¾‹
> def batch_process_example():
>     # ç”¨æˆ·ä¸Šä¼ å¤šä¸ªæ–‡ä»¶
>     uploaded_files = st.file_uploader(
>         "é€‰æ‹©æ–‡æ¡£æ–‡ä»¶", 
>        type=['pdf', 'txt', 'md', 'docx'],
>         accept_multiple_files=True  # å…è®¸å¤šæ–‡ä»¶ä¸Šä¼ 
>     )
> 
>     if uploaded_files:
>         # æ‰¹é‡å¤„ç†
>         with st.spinner("æ­£åœ¨æ‰¹é‡å¤„ç†æ–‡æ¡£..."):
>             results = processor.process_documents_batch(uploaded_files)
> 
>         # æ˜¾ç¤ºå¤„ç†ç»“æœ
>         col1, col2, col3 = st.columns(3)
>         with col1:
>             st.metric("æ€»æ–‡ä»¶æ•°", results['total_files'])
>         with col2:
>             st.metric("æˆåŠŸå¤„ç†", results['processed_files'])
>         with col3:
>             st.metric("å¤„ç†å¤±è´¥", results['failed_files'])
> 
>             # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
>         if results['total_documents'] > 0:
>             st.success(f"æˆåŠŸæå– {results['total_documents']} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
> 
>         # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
>                 if results['errors']:
>             st.error("å¤„ç†å¤±è´¥çš„æ–‡ä»¶:")
>             for error in results['errors']:
>                 st.write(f"- {error['file_name']}: {error['error']}")
> 
>         # è¿”å›æ‰€æœ‰æ–‡æ¡£ä¾›åç»­ä½¿ç”¨
>         return results['all_documents']
> ```

### ç¬¬å…«éƒ¨åˆ†ï¼šåŠŸèƒ½æµ‹è¯•

1ï¼‰æµ‹è¯•ä»£ç 

```python
def test_document_processor():
    """æµ‹è¯•æ–‡æ¡£å¤„ç†å™¨æ ¸å¿ƒåŠŸèƒ½"""
    import logging
    import time
    from pathlib import Path
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger(__name__)
    
    print("=" * 60)
    print("ğŸ“š æ–‡æ¡£å¤„ç†å™¨æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–è®¾ç½®å’Œå¤„ç†å™¨
        from config.settings import Settings
        settings = Settings()
        processor = DocumentProcessor()
        
        # æµ‹è¯•æ–‡ä»¶è·¯å¾„
        test_files_dir = Path("files")
        if not test_files_dir.exists():
            print(f"âŒ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {test_files_dir}")
            return
        
        # è·å–æµ‹è¯•æ–‡ä»¶
        test_files = list(test_files_dir.glob("*"))
        if not test_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ–‡ä»¶")
            return
        
        print(f"ğŸ“ æ‰¾åˆ° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶:")
        for i, file in enumerate(test_files, 1):
            file_size = file.stat().st_size / 1024
            print(f"   {i}. {file.name} ({file_size:.1f} KB)")
        
        print("\n" + "=" * 40)
        print("ğŸ”§ å¼€å§‹åŠŸèƒ½æµ‹è¯•...")
        print("=" * 40)
        
        # 1. æµ‹è¯•å•ä¸ªæ–‡ä»¶å¤„ç†
        print("\nğŸ“„ 1. æµ‹è¯•å•ä¸ªæ–‡ä»¶å¤„ç†")
        print("-" * 30)
        
        test_file = test_files[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶
        print(f"å¤„ç†æ–‡ä»¶: {test_file.name}")
        
        try:
            documents = processor.process_uploaded_file(test_file)
            print(f"âœ… æˆåŠŸå¤„ç†ï¼æå–äº† {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
            
            if documents:
                # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç‰‡æ®µçš„ä¿¡æ¯
                first_doc = documents[0]
                content_preview = first_doc.page_content[:100] + "..." if len(first_doc.page_content) > 100 else first_doc.page_content
                print(f"   ç¬¬ä¸€ä¸ªç‰‡æ®µé¢„è§ˆ: {content_preview}")
                print(f"   ç‰‡æ®µé•¿åº¦: {len(first_doc.page_content)} å­—ç¬¦")
                print(f"   å…ƒæ•°æ®: {first_doc.metadata}")
                
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
        
        # 2. æµ‹è¯•æ–‡æ¡£åˆ†å‰²
        print("\nâœ‚ï¸ 2. æµ‹è¯•æ–‡æ¡£åˆ†å‰²åŠŸèƒ½")
        print("-" * 30)
        
        if 'documents' in locals() and documents:
            try:
                # æµ‹è¯•ä¸åŒçš„åˆ†å‰²å‚æ•°
                test_params = [
                    (500, 50),
                    (1000, 100)
                ]
                
                for chunk_size, overlap in test_params:
                    split_docs = processor.split_documents(documents, chunk_size, overlap)
                    print(f"   chunk_size={chunk_size}, overlap={overlap}: {len(split_docs)} ä¸ªç‰‡æ®µ")
                    
                    if split_docs:
                        avg_size = sum(len(doc.page_content) for doc in split_docs) / len(split_docs)
                        print(f"   å¹³å‡ç‰‡æ®µå¤§å°: {avg_size:.0f} å­—ç¬¦")
                        
            except Exception as e:
                print(f"âŒ åˆ†å‰²å¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()
        
        # 3. æµ‹è¯•æ‰¹é‡å¤„ç†
        print("\nğŸ“¦ 3. æµ‹è¯•æ‰¹é‡å¤„ç†")
        print("-" * 30)
        
        try:
            # æ¨¡æ‹ŸStreamlitçš„UploadedFileå¯¹è±¡
            class MockUploadedFile:
                def __init__(self, file_path):
                    self.name = file_path.name
                    self.type = self._get_file_type(file_path)
                    self.size = file_path.stat().st_size
                    self._file_path = file_path
                    
                def _get_file_type(self, file_path):
                    suffix = file_path.suffix.lower()
                    type_map = {
                        '.pdf': 'application/pdf',
                        '.txt': 'text/plain',
                        '.md': 'text/markdown',
                        '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
                    }
                    return type_map.get(suffix, 'application/octet-stream')
                
                def read(self):
                    return self._file_path.read_bytes()
            
            # åˆ›å»ºæ¨¡æ‹Ÿä¸Šä¼ æ–‡ä»¶åˆ—è¡¨
            mock_files = [MockUploadedFile(f) for f in test_files]
            
            print(f"æ‰¹é‡å¤„ç† {len(mock_files)} ä¸ªæ–‡ä»¶...")
            batch_results = processor.process_documents_batch(mock_files)
            
            print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼")
            print(f"   æ€»æ–‡ä»¶æ•°: {batch_results['total_files']}")
            print(f"   æˆåŠŸå¤„ç†: {batch_results['processed_files']}")
            print(f"   å¤„ç†å¤±è´¥: {batch_results['failed_files']}")
            print(f"   æ€»æ–‡æ¡£ç‰‡æ®µ: {batch_results['total_documents']}")
            
            # æ˜¾ç¤ºå¤±è´¥æ–‡ä»¶ä¿¡æ¯
            if batch_results['errors']:
                print("\n   å¤±è´¥çš„æ–‡ä»¶:")
                for error in batch_results['errors']:
                    print(f"   - {error['file_name']}: {error['error']}")
                    
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
        
        # 4. æµ‹è¯•ç¼“å­˜åŠŸèƒ½
        print("\nğŸ’¾ 4. æµ‹è¯•ç¼“å­˜åŠŸèƒ½")
        print("-" * 30)
        
        try:
            # è·å–ç¼“å­˜ç»Ÿè®¡
            cache_stats = processor.get_cache_stats()
            print(f"âœ… ç¼“å­˜ç»Ÿè®¡:")
            print(f"   ç¼“å­˜å¯ç”¨: {cache_stats['cache_enabled']}")
            print(f"   ç¼“å­˜æ–‡ä»¶æ•°: {cache_stats['cache_files_count']}")
            print(f"   ç¼“å­˜å¤§å°: {cache_stats['cache_total_size_mb']} MB")
            print(f"   è¿‡æœŸæ—¶é—´: {cache_stats['cache_expire_time']} ç§’")
            
            # æµ‹è¯•å†æ¬¡å¤„ç†ç›¸åŒæ–‡ä»¶ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰
            print(f"\n   å†æ¬¡å¤„ç†ç›¸åŒæ–‡ä»¶æµ‹è¯•ç¼“å­˜...")
            start_time = time.time()
            cached_docs = processor.process_uploaded_file(test_files[0])
            cache_time = time.time() - start_time
            
            print(f"   ç¼“å­˜å¤„ç†æ—¶é—´: {cache_time:.3f} ç§’")
            print(f"   ç¼“å­˜æ–‡æ¡£æ•°: {len(cached_docs)}")
            
        except Exception as e:
            print(f"âŒ ç¼“å­˜æµ‹è¯•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
        
        # 5. æµ‹è¯•æ–‡ä»¶ç±»å‹è¯†åˆ«
        print("\nğŸ” 5. æµ‹è¯•æ–‡ä»¶ç±»å‹å¤„ç†")
        print("-" * 30)
        
        supported_types = ['.pdf', '.txt', '.md', '.docx']
        success_count = 0
        
        for file_path in test_files:
            file_ext = file_path.suffix.lower()
            if file_ext in supported_types:
                print(f"   {file_path.name} ({file_ext}): ", end="")
                try:
                    docs = processor.process_uploaded_file(file_path)
                    print(f"âœ… æˆåŠŸ ({len(docs)} ç‰‡æ®µ)")
                    success_count += 1
                except Exception as e:
                    print(f"âŒ å¤±è´¥ ({str(e)})")
        
        print(f"\n   æˆåŠŸå¤„ç†: {success_count}/{len(test_files)} ä¸ªæ–‡ä»¶")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)
        
        # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
        if 'batch_results' in locals():
            print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
            print(f"   å¤„ç†æ–‡ä»¶ç±»å‹: {len(set(f.suffix for f in test_files))}")
            print(f"   æ€»æ–‡æ¡£ç‰‡æ®µ: {batch_results['total_documents']}")
            if batch_results['total_files'] > 0:
                success_rate = (batch_results['processed_files']/batch_results['total_files']*100)
                print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_document_processor()
```

2ï¼‰å‡†å¤‡æµ‹è¯•æ–‡ä»¶ï¼š

![image-20251111195852187](https://fwytech-ai-images.oss-cn-beijing.aliyuncs.com/my/lab-images/image-20251111195852187.png)

3ï¼‰è¿è¡Œæµ‹è¯•ï¼š

```python
uv run python .\utils\document_processor.py
```

4ï¼‰é¢„æœŸè¿è¡Œç»“æœï¼š

```bash
============================================================
ğŸ“š æ–‡æ¡£å¤„ç†å™¨æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•
============================================================
ğŸ“ æ‰¾åˆ° 3 ä¸ªæµ‹è¯•æ–‡ä»¶:
   1. Prompt åˆ†äº«.pdf (1319.1 KB)
   2. xiyouji_sample_01.txt (3.1 KB)
   3. å¤§æ¨¡å‹æ¨ç†åˆ†äº«.docx (2961.4 KB)

========================================
ğŸ”§ å¼€å§‹åŠŸèƒ½æµ‹è¯•...
========================================

ğŸ“„ 1. æµ‹è¯•å•ä¸ªæ–‡ä»¶å¤„ç†
------------------------------
å¤„ç†æ–‡ä»¶: Prompt åˆ†äº«.pdf
2025-11-11 19:53:41,637 - INFO - åŠ è½½PDFæˆåŠŸ: Prompt åˆ†äº«.pdf, é¡µæ•°: 39
2025-11-11 19:53:41,658 - INFO - ä¿å­˜åˆ°ç¼“å­˜æˆåŠŸ: E:\LLM-Code\agentic-rag-case\03-smart-qa-application\data\document_cache\d8f1e90362e800690d03210dfeaaefcb_Prompt åˆ†äº«.pdf.json
2025-11-11 19:53:41,659 - INFO - å¤„ç†æ–‡ä»¶æˆåŠŸ: Prompt åˆ†äº«.pdf, æ–‡æ¡£æ•°é‡: 39
âœ… æˆåŠŸå¤„ç†ï¼æå–äº† 39 ä¸ªæ–‡æ¡£ç‰‡æ®µ
   ç¬¬ä¸€ä¸ªç‰‡æ®µé¢„è§ˆ: Promptåˆ†äº«
ä¸ºä»€ä¹ˆéœ€è¦Prompt
å¤§æ¨¡å‹æœ¬è´¨æ˜¯åŸºäºæ¦‚ç‡çš„è‡ªå›å½’å‡½æ•°ï¼Œé€šè¿‡å‰åºtokené¢„æµ‹åç»­å†…å®¹ã€‚è¿™ç§ç‰¹æ€§å†³å®šäº†
Promptï¼ˆè¾“å…¥æç¤ºï¼‰å¯¹æ¨¡å‹è¾“å‡ºè´¨é‡å…·æœ‰å†³å®šæ€§ä½œç”¨ã€‚
1.èŒƒå¼è½¬æ¢
ï‚·å‚ç±»...
   ç‰‡æ®µé•¿åº¦: 318 å­—ç¬¦
   å…ƒæ•°æ®: {'producer': '', 'creator': 'WPS æ–‡å­—', 'creationdate': '2025-11-11T19:14:02+08:00', 'author': '', 'comments': '', 'company': '', 'keywords': '', 'moddate': '2025-11-11T19:14:02+08:00', 'sourcemodified': "D:20251111191402+08'00'", 'subject': '', 'title': '', 'trapped': '/False', 'source': 'Prompt åˆ†äº«.pdf', 'total_pages': 39, 'page': 0, 'page_label': '1', 'file_type': '.pdf', 'chunk_index': 0, 'total_chunks': 39, 'processing_timestamp': '1762862018.7501686'}

âœ‚ï¸ 2. æµ‹è¯•æ–‡æ¡£åˆ†å‰²åŠŸèƒ½
------------------------------
2025-11-11 19:53:41,663 - INFO - åˆ†å‰²æ–‡æ¡£ï¼Œchunk_size: 500, chunk_overlap: 50
2025-11-11 19:53:41,675 - INFO - æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œç‰‡æ®µæ•°é‡: 67
   chunk_size=500, overlap=50: 67 ä¸ªç‰‡æ®µ
   å¹³å‡ç‰‡æ®µå¤§å°: 339 å­—ç¬¦
2025-11-11 19:53:41,688 - INFO - åˆ†å‰²æ–‡æ¡£ï¼Œchunk_size: 1000, chunk_overlap: 100
2025-11-11 19:53:41,696 - INFO - æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œç‰‡æ®µæ•°é‡: 41
   chunk_size=1000, overlap=100: 41 ä¸ªç‰‡æ®µ
   å¹³å‡ç‰‡æ®µå¤§å°: 537 å­—ç¬¦

ğŸ“¦ 3. æµ‹è¯•æ‰¹é‡å¤„ç†
------------------------------
æ‰¹é‡å¤„ç† 3 ä¸ªæ–‡ä»¶...
2025-11-11 19:53:41,718 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
2025-11-11 19:53:41,719 - INFO - å¤„ç†æ–‡ä»¶æˆåŠŸ: Prompt åˆ†äº«.pdf
2025-11-11 19:53:41,725 - INFO - åŠ è½½æ–‡æœ¬æ–‡ä»¶æˆåŠŸ: xiyouji_sample_01.txt
2025-11-11 19:53:41,737 - INFO - ä¿å­˜åˆ°ç¼“å­˜æˆåŠŸ: E:\LLM-Code\agentic-rag-case\03-smart-qa-application\data\document_cache\61fab260461ac88e619b8f6657565863_xiyouji_sample_01.txt.json
2025-11-11 19:53:41,738 - INFO - å¤„ç†æ–‡ä»¶æˆåŠŸ: xiyouji_sample_01.txt, æ–‡æ¡£æ•°é‡: 1
2025-11-11 19:53:41,738 - INFO - å¤„ç†æ–‡ä»¶æˆåŠŸ: xiyouji_sample_01.txt
2025-11-11 19:53:52,535 - INFO - åŠ è½½Wordæ–‡æ¡£æˆåŠŸ: å¤§æ¨¡å‹æ¨ç†åˆ†äº«.docx
2025-11-11 19:53:52,541 - INFO - ä¿å­˜åˆ°ç¼“å­˜æˆåŠŸ: E:\LLM-Code\agentic-rag-case\03-smart-qa-application\data\document_cache\e6fdb24e18e1a02598cecad0eecee948_å¤§æ¨¡å‹æ¨ç†åˆ†
äº«.docx.json
2025-11-11 19:53:52,542 - INFO - å¤„ç†æ–‡ä»¶æˆåŠŸ: å¤§æ¨¡å‹æ¨ç†åˆ†äº«.docx, æ–‡æ¡£æ•°é‡: 1
2025-11-11 19:53:52,542 - INFO - å¤„ç†æ–‡ä»¶æˆåŠŸ: å¤§æ¨¡å‹æ¨ç†åˆ†äº«.docx
âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼
   æ€»æ–‡ä»¶æ•°: 3
   æˆåŠŸå¤„ç†: 3
   å¤„ç†å¤±è´¥: 0
   æ€»æ–‡æ¡£ç‰‡æ®µ: 41

ğŸ’¾ 4. æµ‹è¯•ç¼“å­˜åŠŸèƒ½
------------------------------
âœ… ç¼“å­˜ç»Ÿè®¡:
   ç¼“å­˜å¯ç”¨: True
   ç¼“å­˜æ–‡ä»¶æ•°: 3
   ç¼“å­˜å¤§å°: 0.07 MB
   è¿‡æœŸæ—¶é—´: 3600 ç§’

   å†æ¬¡å¤„ç†ç›¸åŒæ–‡ä»¶æµ‹è¯•ç¼“å­˜...
2025-11-11 19:53:52,552 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   ç¼“å­˜å¤„ç†æ—¶é—´: 0.006 ç§’
   ç¼“å­˜æ–‡æ¡£æ•°: 39

ğŸ” 5. æµ‹è¯•æ–‡ä»¶ç±»å‹å¤„ç†
------------------------------
2025-11-11 19:53:52,560 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   Prompt åˆ†äº«.pdf (.pdf): âœ… æˆåŠŸ (39 ç‰‡æ®µ)
2025-11-11 19:53:52,562 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 1 ä¸ªæ–‡æ¡£
   xiyouji_sample_01.txt (.txt): âœ… æˆåŠŸ (1 ç‰‡æ®µ)

ğŸ’¾ 4. æµ‹è¯•ç¼“å­˜åŠŸèƒ½
------------------------------
âœ… ç¼“å­˜ç»Ÿè®¡:
   ç¼“å­˜å¯ç”¨: True
   ç¼“å­˜æ–‡ä»¶æ•°: 3
   ç¼“å­˜å¤§å°: 0.07 MB
   è¿‡æœŸæ—¶é—´: 3600 ç§’

   å†æ¬¡å¤„ç†ç›¸åŒæ–‡ä»¶æµ‹è¯•ç¼“å­˜...
2025-11-11 19:53:52,552 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   ç¼“å­˜å¤„ç†æ—¶é—´: 0.006 ç§’
   ç¼“å­˜æ–‡æ¡£æ•°: 39

ğŸ” 5. æµ‹è¯•æ–‡ä»¶ç±»å‹å¤„ç†
------------------------------
2025-11-11 19:53:52,560 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   Prompt åˆ†äº«.pdf (.pdf): âœ… æˆåŠŸ (39 ç‰‡æ®µ)
2025-11-11 19:53:52,562 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 1 ä¸ªæ–‡æ¡£
   xiyouji_sample_01.txt (.txt): âœ… æˆåŠŸ (1 ç‰‡æ®µ)
âœ… ç¼“å­˜ç»Ÿè®¡:
   ç¼“å­˜å¯ç”¨: True
   ç¼“å­˜æ–‡ä»¶æ•°: 3
   ç¼“å­˜å¤§å°: 0.07 MB
   è¿‡æœŸæ—¶é—´: 3600 ç§’

   å†æ¬¡å¤„ç†ç›¸åŒæ–‡ä»¶æµ‹è¯•ç¼“å­˜...
2025-11-11 19:53:52,552 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   ç¼“å­˜å¤„ç†æ—¶é—´: 0.006 ç§’
   ç¼“å­˜æ–‡æ¡£æ•°: 39

ğŸ” 5. æµ‹è¯•æ–‡ä»¶ç±»å‹å¤„ç†
------------------------------
2025-11-11 19:53:52,560 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   Prompt åˆ†äº«.pdf (.pdf): âœ… æˆåŠŸ (39 ç‰‡æ®µ)
2025-11-11 19:53:52,562 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 1 ä¸ªæ–‡æ¡£
   xiyouji_sample_01.txt (.txt): âœ… æˆåŠŸ (1 ç‰‡æ®µ)
   è¿‡æœŸæ—¶é—´: 3600 ç§’

   å†æ¬¡å¤„ç†ç›¸åŒæ–‡ä»¶æµ‹è¯•ç¼“å­˜...
2025-11-11 19:53:52,552 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   ç¼“å­˜å¤„ç†æ—¶é—´: 0.006 ç§’
   ç¼“å­˜æ–‡æ¡£æ•°: 39

ğŸ” 5. æµ‹è¯•æ–‡ä»¶ç±»å‹å¤„ç†
------------------------------
2025-11-11 19:53:52,560 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   Prompt åˆ†äº«.pdf (.pdf): âœ… æˆåŠŸ (39 ç‰‡æ®µ)
2025-11-11 19:53:52,562 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 1 ä¸ªæ–‡æ¡£
   xiyouji_sample_01.txt (.txt): âœ… æˆåŠŸ (1 ç‰‡æ®µ)
2025-11-11 19:53:52,552 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   ç¼“å­˜å¤„ç†æ—¶é—´: 0.006 ç§’
   ç¼“å­˜æ–‡æ¡£æ•°: 39

ğŸ” 5. æµ‹è¯•æ–‡ä»¶ç±»å‹å¤„ç†
------------------------------ 
2025-11-11 19:53:52,560 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   Prompt åˆ†äº«.pdf (.pdf): âœ… æˆåŠŸ (39 ç‰‡æ®µ)
2025-11-11 19:53:52,562 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 1 ä¸ªæ–‡æ¡£
   xiyouji_sample_01.txt (.txt): âœ… æˆåŠŸ (1 ç‰‡æ®µ)
ğŸ” 5. æµ‹è¯•æ–‡ä»¶ç±»å‹å¤„ç†
------------------------------
2025-11-11 19:53:52,560 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   Prompt åˆ†äº«.pdf (.pdf): âœ… æˆåŠŸ (39 ç‰‡æ®µ)
2025-11-11 19:53:52,562 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 1 ä¸ªæ–‡æ¡£
   xiyouji_sample_01.txt (.txt): âœ… æˆåŠŸ (1 ç‰‡æ®µ)
2025-11-11 19:53:52,560 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 39 ä¸ªæ–‡æ¡£
   Prompt åˆ†äº«.pdf (.pdf): âœ… æˆåŠŸ (39 ç‰‡æ®µ)
2025-11-11 19:53:52,562 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 1 ä¸ªæ–‡æ¡£
   xiyouji_sample_01.txt (.txt): âœ… æˆåŠŸ (1 ç‰‡æ®µ)
   xiyouji_sample_01.txt (.txt): âœ… æˆåŠŸ (1 ç‰‡æ®µ)
2025-11-11 19:53:52,573 - INFO - ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: 1 ä¸ªæ–‡æ¡£
   å¤§æ¨¡å‹æ¨ç†åˆ†äº«.docx (.docx): âœ… æˆåŠŸ (1 ç‰‡æ®µ)

   æˆåŠŸå¤„ç†: 3/3 ä¸ªæ–‡ä»¶

============================================================
ğŸ‰ æµ‹è¯•å®Œæˆï¼
============================================================
ğŸ“Š æ€»ä½“ç»Ÿè®¡:
   å¤„ç†æ–‡ä»¶ç±»å‹: 3
   æ€»æ–‡æ¡£ç‰‡æ®µ: 41
   æˆåŠŸç‡: 100.0%
```

## å››ã€å®Œæ•´ä»£ç æ€»ç»“

ä¸Šé¢çš„5ä¸ªéƒ¨åˆ†ç»„æˆäº†å®Œæ•´çš„å·¥å…·ç±»ï¼ˆ653è¡Œï¼‰ï¼š

1. **å¤©æ°”æœåŠ¡åˆå§‹åŒ–**ï¼ˆ62è¡Œï¼‰ï¼šåŸå¸‚ä»£ç æŸ¥è¯¢å’Œç¼“å­˜
2. **å¤©æ°”æŸ¥è¯¢**ï¼ˆ82è¡Œï¼‰ï¼šå½“å‰å¤©æ°”å’Œé¢„æŠ¥
3. **å¤©æ°”æ ¼å¼åŒ–**ï¼ˆ118è¡Œï¼‰ï¼šJSONè½¬æ–‡æœ¬ï¼Œæ·»åŠ å»ºè®®
4. **æ–‡æ¡£å¤„ç†æ ¸å¿ƒ**ï¼ˆ174è¡Œï¼‰ï¼šä¸Šä¼ ã€ç¼“å­˜ã€å¤šæ ¼å¼åŠ è½½
5. **æ‰¹é‡å¤„ç†**ï¼ˆ169è¡Œï¼‰ï¼šç¼“å­˜ç®¡ç†ã€æ‰¹é‡æ–‡æ¡£ã€ç»Ÿè®¡

**æ ¸å¿ƒè®¾è®¡æ¨¡å¼**ï¼š

| æ¨¡å¼ | åº”ç”¨åœºæ™¯ | ä»£ç ä½ç½® |
|------|---------|---------|
| **ç¼“å­˜æ¨¡å¼** | åŸå¸‚ä»£ç ã€æ–‡æ¡£å¤„ç† | `city_cache`ã€`_load_from_cache` |
| **å·¥å‚æ¨¡å¼** | æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åŠ è½½å™¨ | `_process_file_content` |
| **æ¨¡æ¿æ–¹æ³•** | ç»Ÿä¸€å¼‚å¸¸å¤„ç†å’Œæ—¥å¿— | try-except-logger |
| **è£…é¥°å™¨æ¨¡å¼** | ä¸´æ—¶æ–‡ä»¶è‡ªåŠ¨æ¸…ç† | try-finally |

## äº”ã€å®é™…ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šå¤©æ°”æŸ¥è¯¢

```python
from services.weather_tools import WeatherTools

# åˆ›å»ºå·¥å…·
weather = WeatherTools()

# å½“å‰å¤©æ°”
result = weather.get_current_weather("åŒ—äº¬")
print(result)
# è¾“å‡ºï¼š
# ğŸ™ï¸ **åŒ—äº¬å¸‚ åŒ—äº¬** å½“å‰å¤©æ°”
# ğŸŒ¤ï¸ **å¤©æ°”çŠ¶å†µ**: æ™´
# ğŸŒ¡ï¸ **æ°”æ¸©**: 25Â°C
# ...

# å¤©æ°”é¢„æŠ¥
forecast = weather.get_weather_forecast("ä¸Šæµ·", days=3)
print(forecast)
```

### ç¤ºä¾‹2ï¼šæ–‡æ¡£å¤„ç†

```python
from utils.document_processor import DocumentProcessor

# åˆ›å»ºå¤„ç†å™¨
processor = DocumentProcessor()

# å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆStreamlitä¸Šä¼ ï¼‰
uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡£")
if uploaded_file:
    documents = processor.process_uploaded_file(uploaded_file)
    print(f"å¤„ç†æˆåŠŸï¼Œæ–‡æ¡£æ•°é‡: {len(documents)}")
    print(f"ç¬¬ä¸€ä¸ªæ–‡æ¡£å†…å®¹: {documents[0].page_content[:100]}")
    print(f"å…ƒæ•°æ®: {documents[0].metadata}")

# æ‰¹é‡å¤„ç†
uploaded_files = st.file_uploader("ä¸Šä¼ å¤šä¸ªæ–‡æ¡£", accept_multiple_files=True)
if uploaded_files:
    results = processor.process_documents_batch(uploaded_files)
    print(f"æ€»æ–‡ä»¶æ•°: {results['total_files']}")
    print(f"æˆåŠŸå¤„ç†: {results['processed_files']}")
    print(f"å¤±è´¥: {results['failed_files']}")
    print(f"æ€»æ–‡æ¡£æ•°: {results['total_documents']}")
```

### ç¤ºä¾‹3ï¼šç¼“å­˜ç®¡ç†

```python
processor = DocumentProcessor()

# æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
stats = processor.get_cache_stats()
print(f"ç¼“å­˜æ–‡ä»¶æ•°: {stats['cache_files_count']}")
print(f"ç¼“å­˜æ€»å¤§å°: {stats['cache_total_size_mb']} MB")

# æ¸…ç©ºç¼“å­˜
processor.clear_cache()
```

## ä¸ƒã€æœ¬è®²æ€»ç»“

æˆ‘ä»¬å®Œæˆäº†ä¸¤ä¸ªæ ¸å¿ƒå·¥å…·ç±»çš„å®ç°ï¼š

1. **WeatherTools**ï¼ˆ310è¡Œï¼‰ï¼š
   - é«˜å¾·å¤©æ°”APIé›†æˆ
   - åŸå¸‚ä»£ç æŸ¥è¯¢å’Œç¼“å­˜
   - å½“å‰å¤©æ°”å’Œé¢„æŠ¥æŸ¥è¯¢
   - Markdownæ ¼å¼åŒ–è¾“å‡º
   - æ¸©é¦¨æç¤ºç”Ÿæˆ

2. **DocumentProcessor**ï¼ˆ343è¡Œï¼‰ï¼š
   - å¤šæ ¼å¼æ–‡æ¡£åŠ è½½ï¼ˆPDF/TXT/MD/DOCXï¼‰
   - MD5å“ˆå¸Œç¼“å­˜æœºåˆ¶
   - ä¸´æ—¶æ–‡ä»¶ç®¡ç†
   - æ‰¹é‡å¤„ç†å’Œé”™è¯¯æ”¶é›†
   - å…ƒæ•°æ®ç®¡ç†

**å…³é”®æŠ€æœ¯ç‚¹**ï¼š
- å¤–éƒ¨APIè°ƒç”¨ï¼ˆrequests + timeout + raise_for_statusï¼‰
- ç¼“å­˜ä¼˜åŒ–ï¼ˆåŸå¸‚ä»£ç ç¼“å­˜ã€æ–‡æ¡£ç¼“å­˜ï¼‰
- ä¸´æ—¶æ–‡ä»¶ç®¡ç†ï¼ˆfinallyæ¸…ç†ï¼‰
- æ‰¹é‡å¤„ç†ï¼ˆéƒ¨åˆ†å¤±è´¥ä¸å½±å“å…¨å±€ï¼‰
- å…ƒæ•°æ®ç®¡ç†ï¼ˆè¿½æº¯æ€§å’Œè°ƒè¯•ï¼‰

**æœ€ä½³å®è·µ**ï¼š
- è¶…æ—¶è®¾ç½®ï¼ˆ10ç§’ï¼‰
- å¼‚å¸¸åˆ†ç±»ï¼ˆç½‘ç»œé”™è¯¯ vs ä¸šåŠ¡é”™è¯¯ï¼‰
- é˜²å¾¡æ€§ç¼–ç¨‹ï¼ˆ`isdigit()`æ£€æŸ¥ï¼‰
- æ—¥å¿—è®°å½•ï¼ˆæˆåŠŸã€å¤±è´¥ã€è­¦å‘Šï¼‰
- ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯

## è¡¥å……ï¼šé«˜å¾·å¤©æ°”APIæ¥å£è¯·æ±‚ç¤ºä¾‹

> ## ğŸŒ¤ï¸ é«˜å¾·å¤©æ°”APIè¯·æ±‚ç¤ºä¾‹
>
> ### ğŸ“ **1. è·å–åŸå¸‚ä»£ç API**
>
> **è¯·æ±‚URL:**
> ```
> https://restapi.amap.com/v3/config/district
> ```
>
> **è¯·æ±‚å‚æ•°:**
> ```json
> {
>     "keywords": "åŒ—äº¬",
>     "subdistrict": 0,
>     "key": "73053d990f2e27ad6e600344eee77866",
>     "extensions": "base"
> }
> ```
>
> **è¿”å›æ•°æ®:**
> ```json
> {
>     "status": "1",
>     "info": "OK",
>     "infocode": "10000",
>     "count": "1",
>     "suggestion": {},
>     "districts": [
>         {
>             "citycode": "010",
>             "adcode": "110000",
>             "name": "åŒ—äº¬å¸‚",
>             "center": "116.407526,39.90403",
>             "level": "province",
>             "districts": []
>         }
>     ]
> }
> ```
>
> ---
>
> ### ğŸŒ¡ï¸ **2. è·å–å½“å‰å¤©æ°”API**
>
> **è¯·æ±‚URL:**
> ```
> https://restapi.amap.com/v3/weather/weatherInfo
> ```
>
> **è¯·æ±‚å‚æ•°:**
> ```json
> {
>     "city": "110000",
>     "key": "73053d990f2e27ad6e600344eee77866",
>     "extensions": "base"
> }
> ```
>
> **è¿”å›æ•°æ®:**
> ```json
> {
>     "status": "1",
>     "count": "1",
>     "info": "OK",
>     "infocode": "10000",
>     "lives": [
>         {
>             "province": "åŒ—äº¬",
>             "city": "åŒ—äº¬å¸‚",
>             "adcode": "110000",
>             "weather": "æ™´",
>             "temperature": "15",
>             "winddirection": "ä¸œ",
>             "windpower": "â‰¤3",
>             "humidity": "45",
>             "reporttime": "2025-11-11 17:30:00"
>         }
>     ]
> }
> ```
>
> ---
>
> ### ğŸ“… **3. è·å–å¤©æ°”é¢„æŠ¥API**
>
> **è¯·æ±‚URL:**
> ```
> https://restapi.amap.com/v3/weather/weatherInfo
> ```
>
> **è¯·æ±‚å‚æ•°:**
> ```json
> {
>     "city": "110000",
>     "key": "73053d990f2e27ad6e600344eee77866",
>     "extensions": "all"
> }
> ```
>
> **è¿”å›æ•°æ®:**
> ```json
> {
>     "status": "1",
>     "count": "1",
>     "info": "OK",
>     "infocode": "10000",
>     "forecasts": [
>         {
>             "city": "åŒ—äº¬å¸‚",
>             "adcode": "110000",
>             "province": "åŒ—äº¬",
>             "reporttime": "2025-11-11 17:30:00",
>             "casts": [
>                 {
>                     "date": "2025-11-11",
>                     "week": "1",
>                     "dayweather": "æ™´",
>                     "nightweather": "æ™´",
>                     "daytemp": "18",
>                     "nighttemp": "5",
>                     "daywind": "ä¸œ",
>                     "nightwind": "ä¸œ",
>                     "daypower": "â‰¤3",
>                     "nightpower": "â‰¤3"
>                 },
>                 {
>                     "date": "2025-11-12",
>                     "week": "2",
>                     "dayweather": "å¤šäº‘",
>                     "nightweather": "å¤šäº‘",
>                     "daytemp": "16",
>                     "nighttemp": "7",
>                     "daywind": "å—",
>                     "nightwind": "å—",
>                     "daypower": "â‰¤3",
>                     "nightpower": "â‰¤3"
>                 }
>                 // ... æ›´å¤šå¤©æ•°
>             ]
>         }
>     ]
> }
> ```
>
> ---
>
> ### âš ï¸ **4. é”™è¯¯è¯·æ±‚ç¤ºä¾‹**
>
> **è¯·æ±‚å‚æ•°ï¼ˆæ— æ•ˆåŸå¸‚ï¼‰:**
> ```json
> {
>     "city": "999999",
>     "key": "73053d990f2e27ad6e600344eee77866",
>     "extensions": "base"
> }
> ```
>
> **è¿”å›æ•°æ®:**
> ```json
> {
>     "status": "0",
>     "info": "INVALID_PARAMS",
>     "infocode": "10001"
> }
> ```
>
> ## ğŸ“‹ **å…³é”®å­—æ®µè¯´æ˜**
>
> | å­—æ®µ          | è¯´æ˜                     | ç¤ºä¾‹     |
> | ------------- | ------------------------ | -------- |
> | status        | è¯·æ±‚çŠ¶æ€ï¼Œ1=æˆåŠŸï¼Œ0=å¤±è´¥ | "1"      |
> | info          | çŠ¶æ€æè¿°                 | "OK"     |
> | infocode      | çŠ¶æ€ç                    | "10000"  |
> | adcode        | åŸå¸‚ä»£ç                  | "110000" |
> | weather       | å¤©æ°”çŠ¶å†µ                 | "æ™´"     |
> | temperature   | å½“å‰æ¸©åº¦                 | "15"     |
> | winddirection | é£å‘                     | "ä¸œ"     |
> | windpower     | é£åŠ›                     | "â‰¤3"     |
> | humidity      | æ¹¿åº¦                     | "45"     |
>