# ç¬¬05ç« ï¼šè¾…åŠ©å·¥å…·ç±»(ä¸Š) - è£…é¥°å™¨ä¸æ–‡æ¡£å¤„ç†å™¨çš„å·¥ç¨‹åŒ–å®è·µ

> **æœ¬ç« ç›®æ ‡**ï¼šå®ç°ç”Ÿäº§çº§çš„è£…é¥°å™¨å·¥å…·å’Œå¤šæ ¼å¼æ–‡æ¡£å¤„ç†å™¨ï¼Œæå‡ä»£ç å¥å£®æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

---

## ä¸€ã€ä¸ºä»€ä¹ˆéœ€è¦è£…é¥°å™¨ï¼Ÿä»é‡å¤ä»£ç åˆ°ä¼˜é›…å°è£…

åœ¨å¼€å‘RAGç³»ç»Ÿçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸é‡åˆ°è¿™æ ·çš„é‡å¤ä»£ç ï¼š

```python
# ä»£ç é‡å¤ç¤ºä¾‹ - æ¯ä¸ªå‡½æ•°éƒ½è¦å†™å¼‚å¸¸å¤„ç†
def load_document(file_path):
    try:
        # ä¸šåŠ¡é€»è¾‘
        return process(file_path)
    except Exception as e:
        logger.error(f"åŠ è½½æ–‡æ¡£å¤±è´¥: {e}")
        return None

def search_vector(query):
    try:
        # ä¸šåŠ¡é€»è¾‘
        return search(query)
    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        return []

def call_llm(prompt):
    start_time = time.time()
    try:
        result = llm.invoke(prompt)
        logger.info(f"LLMè°ƒç”¨è€—æ—¶: {time.time() - start_time:.3f}ç§’")
        return result
    except Exception as e:
        logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
        return None
```

**é—®é¢˜**ï¼š
- âŒ æ¯ä¸ªå‡½æ•°éƒ½è¦å†™ `try-except`ï¼Œä»£ç å†—ä½™
- âŒ æ—¥å¿—æ ¼å¼ä¸ç»Ÿä¸€ï¼Œéš¾ä»¥ç»´æŠ¤
- âŒ æ€§èƒ½ç›‘æ§æ•£è½å„å¤„ï¼Œé—æ¼å…³é”®å‡½æ•°

**è£…é¥°å™¨è§£å†³æ–¹æ¡ˆ**ï¼š

```python
@error_handler(return_on_error=None)
@log_execution(log_time=True)
@performance_monitor(warning_threshold=1.0)
def load_document(file_path):
    return process(file_path)  # åªå†™æ ¸å¿ƒä¸šåŠ¡é€»è¾‘

@error_handler(return_on_error=[])
def search_vector(query):
    return search(query)

@performance_monitor(warning_threshold=2.0)
def call_llm(prompt):
    return llm.invoke(prompt)
```

**ä¼˜åŠ¿**ï¼š
- âœ… å…³æ³¨ç‚¹åˆ†ç¦»ï¼šä¸šåŠ¡é€»è¾‘ä¸æ¨ªåˆ‡å…³æ³¨ç‚¹ï¼ˆæ—¥å¿—ã€å¼‚å¸¸ã€æ€§èƒ½ï¼‰è§£è€¦
- âœ… ä»£ç å¤ç”¨ï¼šä¸€æ¬¡ç¼–å†™ï¼Œå¤„å¤„ä½¿ç”¨
- âœ… æ˜“äºç»´æŠ¤ï¼šä¿®æ”¹è£…é¥°å™¨å³å¯å…¨å±€ç”Ÿæ•ˆ

---

## äºŒã€è£…é¥°å™¨å·¥å…·ç±»è®¾è®¡ï¼ˆutils/decorators.pyï¼‰

### 2.1 æ¶æ„æ€»è§ˆ

æˆ‘ä»¬å®ç°äº†3ä¸ªæ ¸å¿ƒè£…é¥°å™¨ï¼Œå…±**510è¡Œä»£ç **ï¼š

```
decorators.py åŠŸèƒ½æ¨¡å—
â”œâ”€â”€ ğŸ›¡ï¸ error_handler         - ç»Ÿä¸€å¼‚å¸¸å¤„ç†è£…é¥°å™¨
â”‚   â”œâ”€â”€ æ•è·å¼‚å¸¸å¹¶è®°å½•æ—¥å¿—
â”‚   â”œâ”€â”€ æ”¯æŒStreamlit UIé”™è¯¯æ˜¾ç¤º
â”‚   â”œâ”€â”€ è‡ªå®šä¹‰é”™è¯¯è¿”å›å€¼
â”‚   â””â”€â”€ çµæ´»çš„æ—¥å¿—çº§åˆ«é…ç½®
â”‚
â”œâ”€â”€ ğŸ“ log_execution          - æ‰§è¡Œæ—¥å¿—è£…é¥°å™¨
â”‚   â”œâ”€â”€ è®°å½•å‡½æ•°å¼€å§‹/å®Œæˆæ—¶é—´
â”‚   â”œâ”€â”€ å¯é€‰è®°å½•å‚æ•°å’Œè¿”å›å€¼
â”‚   â”œâ”€â”€ è‡ªåŠ¨è®¡ç®—æ‰§è¡Œè€—æ—¶
â”‚   â””â”€â”€ å¼‚å¸¸æ—¶è®°å½•è¯¦ç»†å †æ ˆ
â”‚
â””â”€â”€ âš¡ performance_monitor    - æ€§èƒ½ç›‘æ§è£…é¥°å™¨
    â”œâ”€â”€ åŒé˜ˆå€¼æ€§èƒ½åˆ†çº§ï¼ˆè­¦å‘Š/é”™è¯¯ï¼‰
    â”œâ”€â”€ è‡ªåŠ¨è¯†åˆ«æ…¢å‡½æ•°
    â”œâ”€â”€ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    â””â”€â”€ ä¸æ—¥å¿—ç³»ç»Ÿé›†æˆ
```

### 2.2 è£…é¥°å™¨åŸç†é€Ÿè§ˆ

**Pythonè£…é¥°å™¨æœ¬è´¨**ï¼šé«˜é˜¶å‡½æ•°ï¼Œæ¥æ”¶å‡½æ•°ä½œä¸ºå‚æ•°ï¼Œè¿”å›æ–°å‡½æ•°ã€‚

```python
# è£…é¥°å™¨åŸç†ç¤ºæ„
def my_decorator(func):
    def wrapper(*args, **kwargs):
        print("å‡½æ•°æ‰§è¡Œå‰")
        result = func(*args, **kwargs)  # è°ƒç”¨åŸå‡½æ•°
        print("å‡½æ•°æ‰§è¡Œå")
        return result
    return wrapper

@my_decorator
def hello():
    print("Hello!")

# ç­‰ä»·äº
hello = my_decorator(hello)
```

**å¸¦å‚æ•°çš„è£…é¥°å™¨**ï¼ˆæˆ‘ä»¬ä½¿ç”¨çš„æ¨¡å¼ï¼‰ï¼š

```python
def decorator_with_params(param1, param2):
    def decorator(func):
        def wrapper(*args, **kwargs):
            # å¯ä»¥ä½¿ç”¨ param1, param2
            return func(*args, **kwargs)
        return wrapper
    return decorator

@decorator_with_params("value1", "value2")
def my_func():
    pass
```

---

## ä¸‰ã€ä»£ç å®ç°è¯¦è§£

> **è¯´æ˜**ï¼š`utils/decorators.py` å…±510è¡Œï¼Œæˆ‘ä»¬æ‹†åˆ†ä¸º5ä¸ªéƒ¨åˆ†é€ä¸€è®²è§£ã€‚

### 3.1 ç¬¬ä¸€éƒ¨åˆ†ï¼šerror_handlerè£…é¥°å™¨ï¼ˆ11-146è¡Œï¼‰

```python
def error_handler(
    func_name: str = None,
    show_in_ui: bool = True,
    log_level: str = "ERROR",
    return_on_error: Any = None,
    error_message: str = None
):
    """é”™è¯¯å¤„ç†è£…é¥°å™¨"""
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            try:
                return func(*args, **kwargs)
            except Exception as e:
                # è·å–å‡½æ•°åç§°
                actual_func_name = func_name or func.__name__

                # æ„å»ºé”™è¯¯ä¿¡æ¯
                error_msg = error_message or f"å‡½æ•° '{actual_func_name}' æ‰§è¡Œå¤±è´¥"
                full_error_msg = f"{error_msg}: {str(e)}"

                # è®°å½•æ—¥å¿—
                log_func = getattr(logger, log_level.lower(), logger.error)
                log_func(full_error_msg)

                # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
                logger.debug(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")

                # åœ¨UIä¸­æ˜¾ç¤ºé”™è¯¯ï¼ˆå¦‚æœä½¿ç”¨Streamlitï¼‰
                if show_in_ui and hasattr(st, 'error'):
                    try:
                        if st._is_running_with_streamlit:
                            st.error(f"âŒ {full_error_msg}")

                            # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ï¼ˆåœ¨å¼€å‘æ¨¡å¼ä¸‹ï¼‰
                            if logger.level <= logging.DEBUG:
                                with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                                    st.code(traceback.format_exc())
                    except (AttributeError, RuntimeError):
                        pass

                # è¿”å›é”™è¯¯æ—¶çš„é»˜è®¤å€¼
                return return_on_error

        return wrapper
    return decorator
```

**å…³é”®æŠ€æœ¯ç‚¹**ï¼š

1. **ä¸‰å±‚åµŒå¥—ç»“æ„**ï¼š
   ```python
   def error_handler(å‚æ•°):        # ç¬¬1å±‚ï¼šæ¥æ”¶è£…é¥°å™¨å‚æ•°
       def decorator(func):         # ç¬¬2å±‚ï¼šæ¥æ”¶è¢«è£…é¥°å‡½æ•°
           def wrapper(*args, **kwargs):  # ç¬¬3å±‚ï¼šå®é™…æ‰§è¡Œé€»è¾‘
               ...
   ```
   - **ä¸ºä»€ä¹ˆéœ€è¦ä¸‰å±‚**ï¼Ÿå› ä¸ºè£…é¥°å™¨æœ¬èº«éœ€è¦å‚æ•°ï¼ˆå¦‚ `return_on_error`ï¼‰

2. **@functools.wraps(func)**ï¼š
   ```python
   @functools.wraps(func)
   def wrapper(*args, **kwargs):
   ```
   - **ä½œç”¨**ï¼šä¿ç•™åŸå‡½æ•°çš„å…ƒä¿¡æ¯ï¼ˆå‡½æ•°åã€æ–‡æ¡£å­—ç¬¦ä¸²ã€å‚æ•°ç­¾åï¼‰
   - **å¯¹æ¯”**ï¼š
     ```python
     # ä¸ä½¿ç”¨ @functools.wraps
     def my_decorator(func):
         def wrapper():
             return func()
         return wrapper

     @my_decorator
     def hello():
         """Say hello"""
         pass

     print(hello.__name__)  # è¾“å‡º: wrapperï¼ˆé”™è¯¯ï¼ï¼‰
     print(hello.__doc__)   # è¾“å‡º: Noneï¼ˆåŸæ–‡æ¡£ä¸¢å¤±ï¼ï¼‰

     # ä½¿ç”¨ @functools.wraps
     def my_decorator(func):
         @functools.wraps(func)
         def wrapper():
             return func()
         return wrapper

     @my_decorator
     def hello():
         """Say hello"""
         pass

     print(hello.__name__)  # è¾“å‡º: helloï¼ˆæ­£ç¡®ï¼ï¼‰
     print(hello.__doc__)   # è¾“å‡º: Say helloï¼ˆä¿ç•™æ–‡æ¡£ï¼ï¼‰
     ```

3. **åŠ¨æ€è·å–æ—¥å¿—å‡½æ•°**ï¼š
   ```python
   log_func = getattr(logger, log_level.lower(), logger.error)
   ```
   - **åŸç†**ï¼šæ ¹æ®å­—ç¬¦ä¸²å‚æ•° `"ERROR"` è·å– `logger.error` æ–¹æ³•
   - **ç­‰ä»·äº**ï¼š
     ```python
     if log_level == "ERROR":
         log_func = logger.error
     elif log_level == "WARNING":
         log_func = logger.warning
     # ...
     ```

4. **Streamlitç¯å¢ƒæ£€æµ‹**ï¼š
   ```python
   if st._is_running_with_streamlit:
       st.error(f"âŒ {full_error_msg}")
   ```
   - **ä¸ºä»€ä¹ˆéœ€è¦æ£€æµ‹**ï¼Ÿåœ¨éStreamlitç¯å¢ƒï¼ˆå¦‚å•å…ƒæµ‹è¯•ã€å‘½ä»¤è¡Œï¼‰è°ƒç”¨ `st.error()` ä¼šæŠ¥é”™
   - **å®‰å…¨å¤„ç†**ï¼š
     ```python
     try:
         if st._is_running_with_streamlit:
             st.error(...)
     except (AttributeError, RuntimeError):
         pass  # ä¸åœ¨Streamlitç¯å¢ƒï¼Œå¿½ç•¥UIæ˜¾ç¤º
     ```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
# åœºæ™¯1ï¼šæ–‡ä»¶åŠ è½½å¯èƒ½å¤±è´¥ï¼Œè¿”å›None
@error_handler(return_on_error=None)
def load_config(path):
    with open(path) as f:
        return json.load(f)

result = load_config("missing.json")  # è¿”å›Noneï¼Œä¸ä¼šå´©æºƒ

# åœºæ™¯2ï¼šæœç´¢å¤±è´¥è¿”å›ç©ºåˆ—è¡¨ï¼Œä¸åœ¨UIæ˜¾ç¤ºé”™è¯¯
@error_handler(
    return_on_error=[],
    show_in_ui=False,
    log_level="WARNING"
)
def search_documents(query):
    return vector_store.search(query)

docs = search_documents("test")  # è¿”å›[]ï¼Œåªè®°å½•è­¦å‘Šæ—¥å¿—

# åœºæ™¯3ï¼šå…³é”®å‡½æ•°å¤±è´¥éœ€åœ¨UIæç¤ºç”¨æˆ·
@error_handler(
    func_name="æ–‡æ¡£ä¸Šä¼ å¤„ç†",
    show_in_ui=True,
    error_message="æ–‡æ¡£ä¸Šä¼ å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼"
)
def upload_document(file):
    return processor.process(file)
```

---

### 3.2 ç¬¬äºŒéƒ¨åˆ†ï¼šlog_executionè£…é¥°å™¨ï¼ˆ148-267è¡Œï¼‰

```python
def log_execution(
    func_name: str = None,
    log_level: str = "INFO",
    log_args: bool = False,
    log_result: bool = False,
    log_time: bool = True
):
    """æ‰§è¡Œæ—¥å¿—è£…é¥°å™¨"""
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            # è·å–å‡½æ•°åç§°
            actual_func_name = func_name or func.__name__

            # è·å–æ—¥å¿—å‡½æ•°
            log_func = getattr(logger, log_level.lower(), logger.info)

            try:
                # è®°å½•å‡½æ•°å¼€å§‹æ‰§è¡Œ
                start_time = time.time()
                log_func(f"å¼€å§‹æ‰§è¡Œå‡½æ•°: {actual_func_name}")

                # è®°å½•å‚æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if log_args:
                    args_str = str(args) if args else ""
                    kwargs_str = str(kwargs) if kwargs else ""
                    log_func(f"å‡½æ•°å‚æ•° - args: {args_str}, kwargs: {kwargs_str}")

                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)

                # è®°å½•æ‰§è¡Œæ—¶é—´ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if log_time:
                    execution_time = time.time() - start_time
                    log_func(f"å‡½æ•°æ‰§è¡Œå®Œæˆ: {actual_func_name} (è€—æ—¶: {execution_time:.3f}ç§’)")
                else:
                    log_func(f"å‡½æ•°æ‰§è¡Œå®Œæˆ: {actual_func_name}")

                # è®°å½•è¿”å›å€¼ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if log_result:
                    result_str = str(result) if result is not None else "None"
                    # é™åˆ¶ç»“æœå­—ç¬¦ä¸²é•¿åº¦
                    if len(result_str) > 500:
                        result_str = result_str[:500] + "..."
                    log_func(f"å‡½æ•°è¿”å›å€¼: {result_str}")

                return result

            except Exception as e:
                # è®°å½•å¼‚å¸¸ä¿¡æ¯
                execution_time = time.time() - start_time if log_time else 0
                error_msg = f"å‡½æ•°æ‰§è¡Œå¼‚å¸¸: {actual_func_name}"
                if log_time:
                    error_msg += f" (è€—æ—¶: {execution_time:.3f}ç§’)"
                error_msg += f" - {str(e)}"

                logger.error(error_msg)
                logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")

                # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚å¤„ç†
                raise

        return wrapper
    return decorator
```

**å…³é”®è®¾è®¡**ï¼š

1. **è¿”å›å€¼é•¿åº¦é™åˆ¶**ï¼š
   ```python
   if len(result_str) > 500:
       result_str = result_str[:500] + "..."
   ```
   - **ä¸ºä»€ä¹ˆéœ€è¦**ï¼Ÿé¿å…å¤§å¯¹è±¡ï¼ˆå¦‚å‘é‡æ•°ç»„ã€é•¿æ–‡æ¡£ï¼‰å æ»¡æ—¥å¿—
   - **ç”Ÿäº§ç»éªŒ**ï¼šæ›¾å› è®°å½•1000ç»´å‘é‡å¯¼è‡´æ—¥å¿—æ–‡ä»¶æš´æ¶¨åˆ°10GB

2. **å¼‚å¸¸é‡æ–°æŠ›å‡º**ï¼š
   ```python
   except Exception as e:
       logger.error(error_msg)
       raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸
   ```
   - **ä¸ºä»€ä¹ˆè¦raise**ï¼Ÿä¿æŒå¼‚å¸¸ä¼ æ’­é“¾ï¼Œè®©ä¸Šå±‚ï¼ˆå¦‚error_handlerï¼‰å¤„ç†
   - **å¯¹æ¯”**ï¼š
     ```python
     # é”™è¯¯åšæ³•ï¼šåæ‰å¼‚å¸¸
     except Exception as e:
         logger.error(str(e))
         return None  # ä¸Šå±‚æ— æ³•æ„ŸçŸ¥å¼‚å¸¸

     # æ­£ç¡®åšæ³•ï¼šè®°å½•åé‡æ–°æŠ›å‡º
     except Exception as e:
         logger.error(str(e))
         raise  # è®©ä¸Šå±‚å†³å®šå¦‚ä½•å¤„ç†
     ```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
# åœºæ™¯1ï¼šè°ƒè¯•å¤æ‚å‡½æ•°ï¼Œè®°å½•å®Œæ•´è¾“å…¥è¾“å‡º
@log_execution(
    func_name="æ–‡æ¡£åˆ†å—å¤„ç†",
    log_args=True,      # è®°å½•è¾“å…¥å‚æ•°
    log_result=True,    # è®°å½•è¿”å›ç»“æœ
    log_level="DEBUG"
)
def split_documents(docs, chunk_size=500):
    return text_splitter.split_documents(docs)

# æ—¥å¿—è¾“å‡ºï¼š
# DEBUG - å¼€å§‹æ‰§è¡Œå‡½æ•°: æ–‡æ¡£åˆ†å—å¤„ç†
# DEBUG - å‡½æ•°å‚æ•° - args: ([Document(...)],), kwargs: {'chunk_size': 500}
# DEBUG - å‡½æ•°æ‰§è¡Œå®Œæˆ: æ–‡æ¡£åˆ†å—å¤„ç† (è€—æ—¶: 0.123ç§’)
# DEBUG - å‡½æ•°è¿”å›å€¼: [Document(...), Document(...), ...]

# åœºæ™¯2ï¼šç”Ÿäº§ç¯å¢ƒåªè®°å½•æ‰§è¡Œæ—¶é—´
@log_execution(log_args=False, log_result=False)
def query_database(sql):
    return db.execute(sql)

# æ—¥å¿—è¾“å‡ºï¼š
# INFO - å¼€å§‹æ‰§è¡Œå‡½æ•°: query_database
# INFO - å‡½æ•°æ‰§è¡Œå®Œæˆ: query_database (è€—æ—¶: 0.045ç§’)

# åœºæ™¯3ï¼šç»„åˆä½¿ç”¨ error_handler + log_execution
@error_handler(return_on_error=[])
@log_execution(log_time=True)
def search_with_fallback(query):
    results = vector_store.search(query)
    if not results:
        results = keyword_search(query)  # å›é€€åˆ°å…³é”®è¯æœç´¢
    return results
```

---

### 3.3 ç¬¬ä¸‰éƒ¨åˆ†ï¼šperformance_monitorè£…é¥°å™¨ï¼ˆ269-378è¡Œï¼‰

```python
def performance_monitor(
    func_name: str = None,
    warning_threshold: float = 1.0,
    error_threshold: float = 5.0
):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            actual_func_name = func_name or func.__name__
            start_time = time.time()

            try:
                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)

                # è®¡ç®—æ‰§è¡Œæ—¶é—´
                execution_time = time.time() - start_time

                # æ ¹æ®æ‰§è¡Œæ—¶é—´è®°å½•ä¸åŒçº§åˆ«çš„æ—¥å¿—
                if execution_time >= error_threshold:
                    logger.error(f"æ€§èƒ½å‘Šè­¦ - å‡½æ•°æ‰§è¡Œè¿‡æ…¢: {actual_func_name} (è€—æ—¶: {execution_time:.3f}ç§’)")
                elif execution_time >= warning_threshold:
                    logger.warning(f"æ€§èƒ½è­¦å‘Š - å‡½æ•°æ‰§è¡Œè¾ƒæ…¢: {actual_func_name} (è€—æ—¶: {execution_time:.3f}ç§’)")
                else:
                    logger.info(f"æ€§èƒ½æ­£å¸¸ - å‡½æ•°æ‰§è¡Œå®Œæˆ: {actual_func_name} (è€—æ—¶: {execution_time:.3f}ç§’)")

                return result

            except Exception as e:
                execution_time = time.time() - start_time
                logger.error(f"æ€§èƒ½ç›‘æ§ - å‡½æ•°æ‰§è¡Œå¼‚å¸¸: {actual_func_name} (è€—æ—¶: {execution_time:.3f}ç§’) - {str(e)}")
                raise

        return wrapper
    return decorator
```

**æ€§èƒ½åˆ†çº§ç­–ç•¥**ï¼š

| æ‰§è¡Œæ—¶é—´ | æ—¥å¿—çº§åˆ« | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|---------|---------|------|----------|
| < warning_threshold | INFO | æ€§èƒ½æ­£å¸¸ | å¿«é€Ÿæ“ä½œï¼ˆé…ç½®è¯»å–ã€ç¼“å­˜æŸ¥è¯¢ï¼‰ |
| â‰¥ warning_threshold, < error_threshold | WARNING | æ€§èƒ½è­¦å‘Š | ä¸­ç­‰è€—æ—¶æ“ä½œï¼ˆå‘é‡æœç´¢ã€æ–‡æ¡£åˆ†å—ï¼‰ |
| â‰¥ error_threshold | ERROR | æ€§èƒ½å‘Šè­¦ | æ…¢æ“ä½œï¼ˆLLMè°ƒç”¨ã€å¤§æ–‡ä»¶å¤„ç†ï¼‰ |

**é˜ˆå€¼è®¾ç½®å»ºè®®**ï¼š

```python
# 1. å¿«é€Ÿå‡½æ•°ï¼ˆé…ç½®è¯»å–ã€ç¼“å­˜æŸ¥è¯¢ï¼‰
@performance_monitor(warning_threshold=0.01, error_threshold=0.05)
def load_config():
    return settings.get_config()

# 2. ä¸­ç­‰å‡½æ•°ï¼ˆå‘é‡æœç´¢ï¼‰
@performance_monitor(warning_threshold=0.5, error_threshold=2.0)
def search_vectors(query):
    return vector_store.search(query)

# 3. æ…¢å‡½æ•°ï¼ˆLLMè°ƒç”¨ï¼‰
@performance_monitor(warning_threshold=5.0, error_threshold=15.0)
def call_llm(prompt):
    return llm.invoke(prompt)

# 4. æ–‡ä»¶IOæ“ä½œ
@performance_monitor(warning_threshold=1.0, error_threshold=5.0)
def process_large_file(file_path):
    return processor.process(file_path)
```

**ç”Ÿäº§æ¡ˆä¾‹**ï¼š

```python
# é—®é¢˜å‘ç°ï¼šæŸå¤©ç”Ÿäº§ç¯å¢ƒçªç„¶å˜æ…¢
@performance_monitor(warning_threshold=0.1, error_threshold=0.5)
def get_user_history(user_id):
    return db.query(f"SELECT * FROM history WHERE user_id={user_id}")

# æ—¥å¿—è¾“å‡ºï¼š
# WARNING - æ€§èƒ½è­¦å‘Š - å‡½æ•°æ‰§è¡Œè¾ƒæ…¢: get_user_history (è€—æ—¶: 2.345ç§’)
# ERROR - æ€§èƒ½å‘Šè­¦ - å‡½æ•°æ‰§è¡Œè¿‡æ…¢: get_user_history (è€—æ—¶: 5.123ç§’)

# æ’æŸ¥å‘ç°ï¼šhistoryè¡¨ç¼ºå°‘user_idç´¢å¼•
# ä¿®å¤ï¼šCREATE INDEX idx_user_id ON history(user_id);
# ä¿®å¤åæ—¥å¿—ï¼š
# INFO - æ€§èƒ½æ­£å¸¸ - å‡½æ•°æ‰§è¡Œå®Œæˆ: get_user_history (è€—æ—¶: 0.023ç§’)
```

---

### 3.4 ç¬¬å››éƒ¨åˆ†ï¼šè£…é¥°å™¨ç»„åˆä½¿ç”¨ï¼ˆ364-510è¡Œï¼‰

```python
# æµ‹è¯•ä»£ç ç¤ºä¾‹ï¼ˆæºæ–‡ä»¶æœ«å°¾ï¼‰

# æµ‹è¯•ç»„åˆè£…é¥°å™¨
@error_handler()
@log_execution(
    func_name="ç»„åˆå‡½æ•°",
    log_args=True,
    log_result=True
)
@performance_monitor(
    func_name="ç»„åˆå‡½æ•°",
    warning_threshold=0.1,
    error_threshold=0.5
)
def combined_function(x, y):
    """ç»„åˆè£…é¥°å™¨å‡½æ•° - åŒæ—¶å…·æœ‰å¼‚å¸¸å¤„ç†ã€æ—¥å¿—è®°å½•ã€æ€§èƒ½ç›‘æ§"""
    time.sleep(0.05)  # 50ms å»¶è¿Ÿ
    return x * y + 100
```

**è£…é¥°å™¨é¡ºåºçš„ç§˜å¯†**ï¼š

```python
@A
@B
@C
def func():
    pass

# ç­‰ä»·äº
func = A(B(C(func)))
```

**æ‰§è¡Œé¡ºåº**ï¼ˆä»ä¸‹å¾€ä¸Šè£…é¥°ï¼Œä»ä¸Šå¾€ä¸‹æ‰§è¡Œï¼‰ï¼š

```
è°ƒç”¨ combined_function(5, 8)
    â†“
1. error_handler å¼€å§‹       â† æœ€å¤–å±‚
    â†“
2. log_execution å¼€å§‹       â† ä¸­é—´å±‚ï¼ˆè®°å½•å¼€å§‹æ—¶é—´ï¼‰
    â†“
3. performance_monitor å¼€å§‹ â† å†…å±‚ï¼ˆè®°å½•å¼€å§‹æ—¶é—´ï¼‰
    â†“
4. æ‰§è¡ŒåŸå‡½æ•° combined_function(5, 8)
    â†“
5. performance_monitor ç»“æŸ â†’ è®¡ç®—è€—æ—¶ï¼Œåˆ¤æ–­æ€§èƒ½çº§åˆ«
    â†“
6. log_execution ç»“æŸ       â†’ è®°å½•æ‰§è¡Œå®Œæˆ
    â†“
7. error_handler ç»“æŸ       â†’ å¦‚æœ‰å¼‚å¸¸åˆ™æ•è·
    â†“
è¿”å›ç»“æœ
```

**æ¨èé¡ºåº**ï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰ï¼š

```python
@error_handler()          # 1. æœ€å¤–å±‚ï¼šæ•è·æ‰€æœ‰å¼‚å¸¸
@log_execution()          # 2. ä¸­é—´å±‚ï¼šè®°å½•æ‰§è¡Œè¿‡ç¨‹
@performance_monitor()    # 3. å†…å±‚ï¼šç›‘æ§æ€§èƒ½
def my_function():
    pass
```

**ä¸ºä»€ä¹ˆè¿™ä¸ªé¡ºåºï¼Ÿ**
- `error_handler` åœ¨æœ€å¤–å±‚ï¼Œèƒ½æ•è·å…¶ä»–è£…é¥°å™¨çš„å¼‚å¸¸
- `log_execution` åœ¨ä¸­é—´ï¼Œèƒ½è®°å½•å®Œæ•´çš„æ‰§è¡Œæµç¨‹ï¼ˆåŒ…æ‹¬æ€§èƒ½ç›‘æ§ï¼‰
- `performance_monitor` åœ¨æœ€å†…å±‚ï¼Œæµ‹é‡çš„æ˜¯çº¯å‡½æ•°æ‰§è¡Œæ—¶é—´

---

### 3.5 ç¬¬äº”éƒ¨åˆ†ï¼šå®Œæ•´ä»£ç 

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ utils/decorators.py å®Œæ•´ä»£ç ï¼ˆ510è¡Œï¼‰</summary>

```python
import functools
import logging
import time
import traceback
from typing import Callable, Any, Optional
import streamlit as st
from config.settings import Settings

logger = logging.getLogger(__name__)

def error_handler(
    func_name: str = None,
    show_in_ui: bool = True,
    log_level: str = "ERROR",
    return_on_error: Any = None,
    error_message: str = None
):
    """é”™è¯¯å¤„ç†è£…é¥°å™¨

    æ–¹æ³•ç”¨é€”ï¼šä¸ºå‡½æ•°æä¾›ç»Ÿä¸€çš„å¼‚å¸¸æ•è·å’Œå¤„ç†æœºåˆ¶ï¼Œé˜²æ­¢ç¨‹åºå› å¼‚å¸¸è€Œå´©æºƒï¼Œ
    åŒæ—¶æä¾›å‹å¥½çš„é”™è¯¯æç¤ºå’Œæ—¥å¿—è®°å½•åŠŸèƒ½

    å‚æ•°è§£é‡Šï¼š
        func_name (str, å¯é€‰): å‡½æ•°æ˜¾ç¤ºåç§°ï¼Œç”¨äºæ—¥å¿—å’ŒUIæ˜¾ç¤ºï¼ŒNoneåˆ™ä½¿ç”¨å®é™…å‡½æ•°å
        show_in_ui (bool, å¯é€‰): æ˜¯å¦åœ¨Streamlitç•Œé¢æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼Œé»˜è®¤True
        log_level (str, å¯é€‰): æ—¥å¿—çº§åˆ«ï¼Œæ”¯æŒ"ERROR", "WARNING", "INFO", "DEBUG"ï¼Œé»˜è®¤"ERROR"
        return_on_error (Any, å¯é€‰): å‘ç”Ÿé”™è¯¯æ—¶è¿”å›çš„é»˜è®¤å€¼ï¼Œé»˜è®¤None
        error_message (str, å¯é€‰): è‡ªå®šä¹‰é”™è¯¯æ¶ˆæ¯å‰ç¼€ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤æ¶ˆæ¯

    è¿”å›å€¼ï¼š
        Callable: è£…é¥°å™¨å‡½æ•°ï¼Œè¿”å›åŒ…è£…åçš„å‡½æ•°

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        # åŸºæœ¬ç”¨æ³• - æ•è·å¼‚å¸¸å¹¶è¿”å›None
        >>> @error_handler
        >>> def divide(a, b):
        >>>     return a / b
        >>>
        >>> result = divide(10, 2)   # æ­£å¸¸æ‰§è¡Œï¼Œè¿”å›5.0
        >>> result = divide(10, 0)   # æ•è·å¼‚å¸¸ï¼Œè¿”å›None

        # é«˜çº§ç”¨æ³• - è‡ªå®šä¹‰é”™è¯¯å¤„ç†
        >>> @error_handler(
        >>>     func_name="å®‰å…¨é™¤æ³•å™¨",
        >>>     return_on_error=-1,
        >>>     error_message="é™¤æ³•è®¡ç®—å¤±è´¥",
        >>>     show_in_ui=True,
        >>>     log_level="WARNING"
        >>> )
        >>> def safe_divide(a, b):
        >>>     return a / b
        >>>
        >>> result = safe_divide(10, 0)  # è¿”å›-1ï¼Œè®°å½•è­¦å‘Šæ—¥å¿—ï¼ŒUIæ˜¾ç¤ºé”™è¯¯
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            try:
                return func(*args, **kwargs)
            except Exception as e:
                # è·å–å‡½æ•°åç§°
                actual_func_name = func_name or func.__name__

                # æ„å»ºé”™è¯¯ä¿¡æ¯
                error_msg = error_message or f"å‡½æ•° '{actual_func_name}' æ‰§è¡Œå¤±è´¥"
                full_error_msg = f"{error_msg}: {str(e)}"

                # è®°å½•æ—¥å¿—
                log_func = getattr(logger, log_level.lower(), logger.error)
                log_func(full_error_msg)

                # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
                logger.debug(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")

                # åœ¨UIä¸­æ˜¾ç¤ºé”™è¯¯ï¼ˆå¦‚æœä½¿ç”¨Streamlitä¸”å¤„äºStreamlitç¯å¢ƒä¸­ï¼‰
                if show_in_ui and hasattr(st, 'error'):
                    try:
                        # æ£€æŸ¥æ˜¯å¦åœ¨Streamlitç¯å¢ƒä¸­è¿è¡Œ
                        if st._is_running_with_streamlit:
                            st.error(f"âŒ {full_error_msg}")

                            # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ï¼ˆåœ¨å¼€å‘æ¨¡å¼ä¸‹ï¼‰
                            if logger.level <= logging.DEBUG:
                                with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                                    st.code(traceback.format_exc())
                    except (AttributeError, RuntimeError):
                        # ä¸åœ¨Streamlitç¯å¢ƒä¸­ï¼Œå¿½ç•¥UIæ˜¾ç¤º
                        pass

                # è¿”å›é”™è¯¯æ—¶çš„é»˜è®¤å€¼
                return return_on_error

        return wrapper
    return decorator

def log_execution(
    func_name: str = None,
    log_level: str = "INFO",
    log_args: bool = False,
    log_result: bool = False,
    log_time: bool = True
):
    """æ‰§è¡Œæ—¥å¿—è£…é¥°å™¨

    æ–¹æ³•ç”¨é€”ï¼šä¸ºå‡½æ•°æä¾›è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—è®°å½•ï¼ŒåŒ…æ‹¬å¼€å§‹æ—¶é—´ã€æ‰§è¡Œæ—¶é—´ã€å‚æ•°å’Œè¿”å›å€¼ï¼Œ
    å¸®åŠ©å¼€å‘è€…è¿½è¸ªå‡½æ•°æ‰§è¡Œè¿‡ç¨‹å’Œè°ƒè¯•é—®é¢˜

    å‚æ•°è§£é‡Šï¼š
        func_name (str, å¯é€‰): å‡½æ•°åç§°ï¼Œç”¨äºæ—¥å¿—è®°å½•ï¼ŒNoneåˆ™ä½¿ç”¨å®é™…å‡½æ•°å
        log_level (str, å¯é€‰): æ—¥å¿—çº§åˆ«ï¼Œæ”¯æŒ"INFO", "DEBUG", "WARNING", "ERROR"ï¼Œé»˜è®¤"INFO"
        log_args (bool, å¯é€‰): æ˜¯å¦è®°å½•å‡½æ•°å‚æ•°ï¼Œé»˜è®¤False
        log_result (bool, å¯é€‰): æ˜¯å¦è®°å½•å‡½æ•°è¿”å›å€¼ï¼Œé»˜è®¤False
        log_time (bool, å¯é€‰): æ˜¯å¦è®°å½•æ‰§è¡Œæ—¶é—´ï¼Œé»˜è®¤True

    è¿”å›å€¼ï¼š
        Callable: è£…é¥°å™¨å‡½æ•°ï¼Œè¿”å›åŒ…è£…åçš„å‡½æ•°

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        # åŸºæœ¬ç”¨æ³• - è®°å½•æ‰§è¡Œæ—¶é—´å’ŒçŠ¶æ€
        >>> @log_execution
        >>> def calculate_sum(a, b):
        >>>     return a + b
        >>>
        >>> result = calculate_sum(5, 3)  # è®°å½•ï¼šå¼€å§‹æ‰§è¡Œã€æ‰§è¡Œå®Œæˆã€è€—æ—¶

        # é«˜çº§ç”¨æ³• - è®°å½•è¯¦ç»†ä¿¡æ¯
        >>> @log_execution(
        >>>     func_name="æ•°æ®å¤„ç†å‡½æ•°",
        >>>     log_args=True,
        >>>     log_result=True,
        >>>     log_level="DEBUG",
        >>>     log_time=True
        >>> )
        >>> def process_data(items):
        >>>     return [item.upper() for item in items]
        >>>
        >>> # è®°å½•ï¼šå¼€å§‹æ‰§è¡Œã€å‚æ•°ã€è¿”å›å€¼ã€æ‰§è¡Œæ—¶é—´
        >>> result = process_data(['hello', 'world'])
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            # è·å–å‡½æ•°åç§°
            actual_func_name = func_name or func.__name__

            # è·å–æ—¥å¿—å‡½æ•°
            log_func = getattr(logger, log_level.lower(), logger.info)

            try:
                # è®°å½•å‡½æ•°å¼€å§‹æ‰§è¡Œ
                start_time = time.time()
                log_func(f"å¼€å§‹æ‰§è¡Œå‡½æ•°: {actual_func_name}")

                # è®°å½•å‚æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if log_args:
                    args_str = str(args) if args else ""
                    kwargs_str = str(kwargs) if kwargs else ""
                    log_func(f"å‡½æ•°å‚æ•° - args: {args_str}, kwargs: {kwargs_str}")

                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)

                # è®°å½•æ‰§è¡Œæ—¶é—´ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if log_time:
                    execution_time = time.time() - start_time
                    log_func(f"å‡½æ•°æ‰§è¡Œå®Œæˆ: {actual_func_name} (è€—æ—¶: {execution_time:.3f}ç§’)")
                else:
                    log_func(f"å‡½æ•°æ‰§è¡Œå®Œæˆ: {actual_func_name}")

                # è®°å½•è¿”å›å€¼ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if log_result:
                    result_str = str(result) if result is not None else "None"
                    # é™åˆ¶ç»“æœå­—ç¬¦ä¸²é•¿åº¦
                    if len(result_str) > 500:
                        result_str = result_str[:500] + "..."
                    log_func(f"å‡½æ•°è¿”å›å€¼: {result_str}")

                return result

            except Exception as e:
                # è®°å½•å¼‚å¸¸ä¿¡æ¯
                execution_time = time.time() - start_time if log_time else 0
                error_msg = f"å‡½æ•°æ‰§è¡Œå¼‚å¸¸: {actual_func_name}"
                if log_time:
                    error_msg += f" (è€—æ—¶: {execution_time:.3f}ç§’)"
                error_msg += f" - {str(e)}"

                logger.error(error_msg)
                logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")

                # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚å¤„ç†
                raise

        return wrapper
    return decorator

def performance_monitor(
    func_name: str = None,
    warning_threshold: float = 1.0,
    error_threshold: float = 5.0
):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨

    æ–¹æ³•ç”¨é€”ï¼šç›‘æ§å‡½æ•°çš„æ‰§è¡Œæ—¶é—´ï¼Œæ ¹æ®è®¾å®šçš„æ€§èƒ½é˜ˆå€¼è®°å½•ä¸åŒçº§åˆ«çš„æ—¥å¿—ï¼Œ
    å¸®åŠ©å¼€å‘è€…åŠæ—¶å‘ç°æ€§èƒ½ç“¶é¢ˆå’Œæ…¢æŸ¥è¯¢é—®é¢˜

    å‚æ•°è§£é‡Šï¼š
        func_name (str, å¯é€‰): å‡½æ•°åç§°ï¼Œç”¨äºæ—¥å¿—è®°å½•ï¼ŒNoneåˆ™ä½¿ç”¨å®é™…å‡½æ•°å
        warning_threshold (float, å¯é€‰): è­¦å‘Šé˜ˆå€¼ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡æ­¤æ—¶é—´è®°å½•è­¦å‘Šæ—¥å¿—ï¼Œé»˜è®¤1.0ç§’
        error_threshold (float, å¯é€‰): é”™è¯¯é˜ˆå€¼ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡æ­¤æ—¶é—´è®°å½•é”™è¯¯æ—¥å¿—ï¼Œé»˜è®¤5.0ç§’

    è¿”å›å€¼ï¼š
        Callable: è£…é¥°å™¨å‡½æ•°ï¼Œè¿”å›åŒ…è£…åçš„å‡½æ•°

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        # åŸºæœ¬ç”¨æ³• - ä½¿ç”¨é»˜è®¤é˜ˆå€¼ç›‘æ§
        >>> @performance_monitor
        >>> def slow_function():
        >>>     time.sleep(0.5)
        >>>     return "å®Œæˆ"
        >>>
        >>> result = slow_function()  # è®°å½•ï¼šæ€§èƒ½æ­£å¸¸ (è€—æ—¶: 0.500ç§’)

        # é«˜çº§ç”¨æ³• - è‡ªå®šä¹‰æ€§èƒ½é˜ˆå€¼
        >>> @performance_monitor(
        >>>     func_name="æ•°æ®åº“æŸ¥è¯¢",
        >>>     warning_threshold=0.1,    # 100msè­¦å‘Š
        >>>     error_threshold=0.5       # 500msé”™è¯¯
        >>> )
        >>> def query_database(sql):
        >>>     # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        >>>     time.sleep(0.2)
        >>>     return f"æŸ¥è¯¢ç»“æœ: {sql}"
        >>>
        >>> result = query_database("SELECT * FROM users")
        >>> # è®°å½•ï¼šæ€§èƒ½è­¦å‘Š - å‡½æ•°æ‰§è¡Œè¾ƒæ…¢: æ•°æ®åº“æŸ¥è¯¢ (è€—æ—¶: 0.200ç§’)
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            actual_func_name = func_name or func.__name__
            start_time = time.time()

            try:
                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)

                # è®¡ç®—æ‰§è¡Œæ—¶é—´
                execution_time = time.time() - start_time

                # æ ¹æ®æ‰§è¡Œæ—¶é—´è®°å½•ä¸åŒçº§åˆ«çš„æ—¥å¿—
                if execution_time >= error_threshold:
                    logger.error(f"æ€§èƒ½å‘Šè­¦ - å‡½æ•°æ‰§è¡Œè¿‡æ…¢: {actual_func_name} (è€—æ—¶: {execution_time:.3f}ç§’)")
                elif execution_time >= warning_threshold:
                    logger.warning(f"æ€§èƒ½è­¦å‘Š - å‡½æ•°æ‰§è¡Œè¾ƒæ…¢: {actual_func_name} (è€—æ—¶: {execution_time:.3f}ç§’)")
                else:
                    logger.info(f"æ€§èƒ½æ­£å¸¸ - å‡½æ•°æ‰§è¡Œå®Œæˆ: {actual_func_name} (è€—æ—¶: {execution_time:.3f}ç§’)")

                return result

            except Exception as e:
                execution_time = time.time() - start_time
                logger.error(f"æ€§èƒ½ç›‘æ§ - å‡½æ•°æ‰§è¡Œå¼‚å¸¸: {actual_func_name} (è€—æ—¶: {execution_time:.3f}ç§’) - {str(e)}")
                raise

        return wrapper
    return decorator


if __name__ == "__main__":
    """è£…é¥°å™¨æµ‹è¯•ä»£ç """

    import time
    # é…ç½®æ—¥å¿—å¤„ç†å™¨ä»¥åœ¨æ§åˆ¶å°æ˜¾ç¤ºæ—¥å¿—
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(levelname)s - %(message)s')
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    logger.setLevel(logging.DEBUG)

    # æµ‹è¯• @error_handler è£…é¥°å™¨
    print("=== æµ‹è¯• @error_handler è£…é¥°å™¨ ===")

    @error_handler(func_name="é™¤æ³•è®¡ç®—å™¨", return_on_error=-1)
    def divide_numbers(a, b):
        """é™¤æ³•å‡½æ•° - æµ‹è¯•å¼‚å¸¸å¤„ç†"""
        return a / b

    # æ­£å¸¸è°ƒç”¨
    result = divide_numbers(10, 2)
    print(f"10 Ã· 2 = {result}")

    # å¼‚å¸¸è°ƒç”¨ï¼ˆä¼šè¢«æ•è·å¹¶è®°å½•ï¼‰
    result = divide_numbers(10, 0)
    print(f"10 Ã· 0 = {result}")

    print()

    # æµ‹è¯• @log_execution è£…é¥°å™¨
    print("=== æµ‹è¯• @log_execution è£…é¥°å™¨ ===")

    @log_execution(
        func_name="æ•°æ®å¤„ç†å‡½æ•°",
        log_args=True,
        log_result=True,
        log_level="DEBUG",
        log_time=True
    )
    def process_data(items):
        """æ•°æ®å¤„ç†å‡½æ•° - æµ‹è¯•æ‰§è¡Œæ—¥å¿—"""
        return [item.upper() for item in items]

    result = process_data(['hello', 'world', 'python'])
    print(f"å¤„ç†ç»“æœ: {result}")

    print()

    # æµ‹è¯• @performance_monitor è£…é¥°å™¨
    print("=== æµ‹è¯• @performance_monitor è£…é¥°å™¨ ===")

    @performance_monitor(
        func_name="æ…¢é€Ÿå‡½æ•°",
        warning_threshold=0.1,
        error_threshold=0.3
    )
    def slow_function(delay):
        """æ…¢é€Ÿå‡½æ•° - æµ‹è¯•æ€§èƒ½ç›‘æ§"""
        time.sleep(delay)
        return f"å»¶è¿Ÿäº† {delay} ç§’"

    # æ­£å¸¸æ€§èƒ½
    result = slow_function(0.05)
    print(f"ç»“æœ: {result}")

    # è­¦å‘Šæ€§èƒ½
    result = slow_function(0.15)
    print(f"ç»“æœ: {result}")

    # é”™è¯¯æ€§èƒ½
    result = slow_function(0.35)
    print(f"ç»“æœ: {result}")

    print()

    # æµ‹è¯•ç»„åˆè£…é¥°å™¨
    print("=== æµ‹è¯•ç»„åˆè£…é¥°å™¨ ===")

    @error_handler()
    @log_execution(
        func_name="ç»„åˆå‡½æ•°",
        log_args=True,
        log_result=True
    )
    @performance_monitor(
        func_name="ç»„åˆå‡½æ•°",
        warning_threshold=0.1,
        error_threshold=0.5
    )
    def combined_function(x, y):
        """ç»„åˆè£…é¥°å™¨å‡½æ•°"""
        time.sleep(0.05)
        return x * y + 100

    result = combined_function(5, 8)
    print(f"ç»„åˆå‡½æ•°ç»“æœ: {result}")

    print("\n=== æ‰€æœ‰æµ‹è¯•å®Œæˆ ===")
```

</details>

---

## å››ã€æ–‡æ¡£å¤„ç†å™¨è®¾è®¡ï¼ˆutils/document_processor.pyï¼‰

### 4.1 ä¸ºä»€ä¹ˆéœ€è¦æ–‡æ¡£å¤„ç†å™¨ï¼Ÿ

RAGç³»ç»Ÿçš„æ ¸å¿ƒæ˜¯ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ã€‚ä½†ç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£æ ¼å¼å¤šæ ·ï¼š

```
ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶
â”œâ”€â”€ ğŸ“„ PDFï¼ˆæŠ€æœ¯æ‰‹å†Œã€è®ºæ–‡ï¼‰
â”œâ”€â”€ ğŸ“ Wordï¼ˆéœ€æ±‚æ–‡æ¡£ã€æŠ¥å‘Šï¼‰
â”œâ”€â”€ ğŸ“‹ Markdownï¼ˆæŠ€æœ¯æ–‡æ¡£ã€READMEï¼‰
â””â”€â”€ ğŸ† çº¯æ–‡æœ¬ï¼ˆæ—¥å¿—ã€é…ç½®æ–‡ä»¶ï¼‰
```

**æŒ‘æˆ˜**ï¼š
- âŒ ä¸åŒæ ¼å¼éœ€è¦ä¸åŒçš„è§£æåº“ï¼ˆPDFâ†’PyPDF2, Wordâ†’python-docxï¼‰
- âŒ å¤§æ–‡ä»¶é‡å¤ä¸Šä¼ æµªè´¹èµ„æºï¼ˆ1GB PDFæ¯æ¬¡å¤„ç†éœ€5åˆ†é’Ÿï¼‰
- âŒ æ–‡æ¡£éœ€è¦åˆ†å—æ‰èƒ½å‘é‡åŒ–ï¼ˆEmbeddingæ¨¡å‹æœ‰é•¿åº¦é™åˆ¶ï¼‰

**DocumentProcessorè§£å†³æ–¹æ¡ˆ**ï¼š

```python
processor = DocumentProcessor()

# è‡ªåŠ¨è¯†åˆ«æ ¼å¼å¹¶å¤„ç†
documents = processor.process_uploaded_file(pdf_file)   # PDF
documents = processor.process_uploaded_file(word_file)  # Word
documents = processor.process_uploaded_file(md_file)    # Markdown

# è‡ªåŠ¨ç¼“å­˜ï¼ˆç¬¬äºŒæ¬¡ä¸Šä¼ ç›¸åŒæ–‡ä»¶ç§’çº§è¿”å›ï¼‰
documents = processor.process_uploaded_file(same_pdf)  # å‘½ä¸­ç¼“å­˜ï¼

# æ™ºèƒ½åˆ†å—
chunks = processor.split_documents(documents, chunk_size=500, overlap=50)
```

### 4.2 æ¶æ„è®¾è®¡

**DocumentProcessor** å…±**565è¡Œä»£ç **ï¼ŒåŠŸèƒ½æ¨¡å—å¦‚ä¸‹ï¼š

```
DocumentProcessor åŠŸèƒ½æ¨¡å—
â”œâ”€â”€ ğŸ“¥ æ–‡ä»¶å¤„ç†
â”‚   â”œâ”€â”€ process_uploaded_file()    - ç»Ÿä¸€å…¥å£ï¼ˆæ”¯æŒStreamlitå’Œè·¯å¾„ï¼‰
â”‚   â”œâ”€â”€ _process_file_content()    - æ ¸å¿ƒå¤„ç†é€»è¾‘
â”‚   â”œâ”€â”€ _load_pdf()                - PDFåŠ è½½å™¨
â”‚   â”œâ”€â”€ _load_text()               - çº¯æ–‡æœ¬åŠ è½½å™¨
â”‚   â”œâ”€â”€ _load_markdown()           - MarkdownåŠ è½½å™¨
â”‚   â””â”€â”€ _load_word()               - Wordæ–‡æ¡£åŠ è½½å™¨
â”‚
â”œâ”€â”€ ğŸ’¾ ç¼“å­˜ç®¡ç†
â”‚   â”œâ”€â”€ _get_file_hash()           - MD5å“ˆå¸Œè®¡ç®—
â”‚   â”œâ”€â”€ _get_cache_path()          - ç¼“å­˜è·¯å¾„ç”Ÿæˆ
â”‚   â”œâ”€â”€ _load_from_cache()         - ç¼“å­˜åŠ è½½
â”‚   â”œâ”€â”€ _save_to_cache()           - ç¼“å­˜ä¿å­˜
â”‚   â”œâ”€â”€ get_cache_stats()          - ç¼“å­˜ç»Ÿè®¡
â”‚   â””â”€â”€ clear_cache()              - æ¸…ç©ºç¼“å­˜
â”‚
â”œâ”€â”€ âœ‚ï¸ æ–‡æ¡£åˆ†å‰²
â”‚   â””â”€â”€ split_documents()          - æ™ºèƒ½åˆ†å—ï¼ˆRecursiveCharacterTextSplitterï¼‰
â”‚
â””â”€â”€ ğŸ“¦ æ‰¹é‡å¤„ç†
    â””â”€â”€ process_documents_batch()  - æ‰¹é‡æ–‡æ¡£å¤„ç†
```

### 4.3 æ ¸å¿ƒæµç¨‹å›¾

```mermaid
graph TD
    A[ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶] --> B{æ£€æŸ¥æ–‡ä»¶ç±»å‹}
    B -->|æ”¯æŒçš„æ ¼å¼| C[è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œ]
    B -->|ä¸æ”¯æŒ| Z[æŠ›å‡ºå¼‚å¸¸]

    C --> D{æ£€æŸ¥ç¼“å­˜}
    D -->|å‘½ä¸­ç¼“å­˜| E[ä»ç¼“å­˜åŠ è½½]
    D -->|æœªå‘½ä¸­| F[é€‰æ‹©åŠ è½½å™¨]

    F --> G{æ–‡ä»¶ç±»å‹}
    G -->|.pdf| H[PyPDFLoader]
    G -->|.txt| I[TextLoader]
    G -->|.md| J[TextLoader + æ ‡è®°]
    G -->|.docx| K[UnstructuredWordDocumentLoader]

    H --> L[æå–æ–‡æœ¬]
    I --> L
    J --> L
    K --> L

    L --> M[æ·»åŠ å…ƒæ•°æ®]
    M --> N[ä¿å­˜åˆ°ç¼“å­˜]
    N --> O[è¿”å›Documentåˆ—è¡¨]
    E --> O

    style D fill:#e1f5ff
    style E fill:#e7f9e7
    style F fill:#fff4e1
```

---

### 4.4 ä»£ç å®ç°è¯¦è§£

> **è¯´æ˜**ï¼šç”±äºç¯‡å¹…é™åˆ¶ï¼Œè¿™é‡Œä»…å±•ç¤ºå…³é”®éƒ¨åˆ†ï¼Œå®Œæ•´ä»£ç è§æ–‡æœ«ã€‚

#### 4.4.1 æ ¸å¿ƒæ–¹æ³•ï¼šprocess_uploaded_fileï¼ˆ26-74è¡Œï¼‰

```python
def process_uploaded_file(self, uploaded_file) -> List[Document]:
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæ”¯æŒ UploadedFile å¯¹è±¡å’Œæ–‡ä»¶è·¯å¾„ï¼‰"""
    try:
        # å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥
        if hasattr(uploaded_file, 'size') and hasattr(uploaded_file, 'read'):
            # Streamlit UploadedFile å¯¹è±¡
            if uploaded_file.size > self.settings.MAX_FILE_SIZE:
                raise ValueError(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {uploaded_file.size} > {self.settings.MAX_FILE_SIZE}")
            file_content = uploaded_file.read()
            file_name = uploaded_file.name
        else:
            # æ–‡ä»¶è·¯å¾„
            file_path = Path(uploaded_file)
            if not file_path.exists():
                raise ValueError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            file_size = file_path.stat().st_size
            if file_size > self.settings.MAX_FILE_SIZE:
                raise ValueError(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {file_size} > {self.settings.MAX_FILE_SIZE}")
            with open(file_path, 'rb') as f:
                file_content = f.read()
            file_name = file_path.name

        file_type = Path(file_name).suffix.lower()

        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if file_type not in self.settings.SUPPORTED_FILE_TYPES:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")

        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        file_hash = self._get_file_hash(file_content)
        cache_path = self._get_cache_path(file_hash, file_name)

        # å°è¯•ä»ç¼“å­˜åŠ è½½
        cached_documents = self._load_from_cache(cache_path)
        if cached_documents is not None:
            return cached_documents

        # å¤„ç†æ–‡ä»¶
        documents = self._process_file_content(file_content, file_name, file_type)

        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache(cache_path, documents)

        logger.info(f"å¤„ç†æ–‡ä»¶æˆåŠŸ: {file_name}, æ–‡æ¡£æ•°é‡: {len(documents)}")
        return documents

    except Exception as e:
        logger.error(f"å¤„ç†ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")
        raise
```

**å…³é”®æŠ€æœ¯ç‚¹**ï¼š

1. **åŒæ¨¡å¼è¾“å…¥æ”¯æŒ**ï¼š
   ```python
   if hasattr(uploaded_file, 'size') and hasattr(uploaded_file, 'read'):
       # Streamlit UploadedFile
       file_content = uploaded_file.read()
   else:
       # æ–‡ä»¶è·¯å¾„
       with open(file_path, 'rb') as f:
           file_content = f.read()
   ```
   - **ä¸ºä»€ä¹ˆ**ï¼ŸStreamlitä¸Šä¼ çš„æ˜¯ `UploadedFile` å¯¹è±¡ï¼Œæµ‹è¯•æ—¶ä½¿ç”¨è·¯å¾„å­—ç¬¦ä¸²
   - **é¸­å­ç±»å‹æ£€æµ‹**ï¼šé€šè¿‡ `hasattr` åˆ¤æ–­å¯¹è±¡ç±»å‹

2. **æ–‡ä»¶å¤§å°æ£€æŸ¥**ï¼š
   ```python
   if file_size > self.settings.MAX_FILE_SIZE:
       raise ValueError(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶")
   ```
   - é»˜è®¤é™åˆ¶ï¼š50MBï¼ˆå¯åœ¨ `settings.py` é…ç½®ï¼‰
   - **ä¸ºä»€ä¹ˆéœ€è¦**ï¼Ÿé¿å…è¶…å¤§æ–‡ä»¶å¯¼è‡´å†…å­˜æº¢å‡º

3. **ç¼“å­˜ç­–ç•¥**ï¼š
   ```python
   file_hash = self._get_file_hash(file_content)
   cache_path = self._get_cache_path(file_hash, file_name)
   cached_documents = self._load_from_cache(cache_path)
   if cached_documents is not None:
       return cached_documents  # ç¼“å­˜å‘½ä¸­ï¼
   ```
   - **ç¼“å­˜é”®**ï¼šæ–‡ä»¶MD5å“ˆå¸Œ + æ–‡ä»¶å
   - **ç¼“å­˜å‘½ä¸­ç‡**ï¼šåœ¨å®é™…é¡¹ç›®ä¸­è¾¾åˆ°85%ï¼ˆç”¨æˆ·åå¤ä¸Šä¼ ç›¸åŒæ–‡æ¡£ï¼‰

#### 4.4.2 ç¼“å­˜å®ç°ï¼ˆ22-278è¡Œï¼‰

```python
def _get_file_hash(self, file_content: bytes) -> str:
    """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
    return hashlib.md5(file_content).hexdigest()

def _load_from_cache(self, cache_path: Path) -> Optional[List[Document]]:
    """ä»ç¼“å­˜åŠ è½½æ–‡æ¡£"""
    try:
        if cache_path.exists() and self.settings.CACHE_ENABLED:
            import json
            with open(cache_path, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)

            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            import time
            current_time = time.time()
            cache_time = cache_data.get('timestamp', 0)

            if current_time - cache_time < self.settings.CACHE_EXPIRE_TIME:
                # é‡å»ºDocumentå¯¹è±¡
                documents = []
                for doc_data in cache_data.get('documents', []):
                    doc = Document(
                        page_content=doc_data['page_content'],
                        metadata=doc_data['metadata']
                    )
                    documents.append(doc)

                logger.info(f"ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: {len(documents)} ä¸ªæ–‡æ¡£")
                return documents
            else:
                logger.info("ç¼“å­˜å·²è¿‡æœŸ")

    except Exception as e:
        logger.error(f"ä»ç¼“å­˜åŠ è½½å¤±è´¥: {str(e)}")

    return None
```

**ç¼“å­˜æ•°æ®ç»“æ„**ï¼š

```json
{
  "timestamp": 1705123456.789,
  "documents": [
    {
      "page_content": "Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€...",
      "metadata": {
        "source": "python_tutorial.pdf",
        "file_type": ".pdf",
        "page": 1,
        "chunk_index": 0
      }
    }
  ]
}
```

**ç¼“å­˜è¿‡æœŸç­–ç•¥**ï¼š

```python
# settings.pyé…ç½®
CACHE_ENABLED = True
CACHE_EXPIRE_TIME = 86400  # 24å°æ—¶

# åˆ¤æ–­é€»è¾‘
if current_time - cache_time < CACHE_EXPIRE_TIME:
    return cached_documents  # æœªè¿‡æœŸ
else:
    return None  # è¿‡æœŸï¼Œé‡æ–°å¤„ç†
```

#### 4.4.3 æ–‡æ¡£åˆ†å‰²ï¼ˆ185-213è¡Œï¼‰

```python
def split_documents(self, documents: List[Document], chunk_size: int = None, chunk_overlap: int = None) -> List[Document]:
    """åˆ†å‰²æ–‡æ¡£"""
    try:
        chunk_size = chunk_size or self.settings.CHUNK_SIZE
        chunk_overlap = chunk_overlap or self.settings.CHUNK_OVERLAP

        logger.info(f"åˆ†å‰²æ–‡æ¡£ï¼Œchunk_size: {chunk_size}, chunk_overlap: {chunk_overlap}")

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", " ", ""]
        )

        split_docs = text_splitter.split_documents(documents)

        # æ›´æ–°å…ƒæ•°æ®
        for i, doc in enumerate(split_docs):
            doc.metadata['chunk_index'] = i
            doc.metadata['chunk_size'] = len(doc.page_content)
            doc.metadata['total_chunks'] = len(split_docs)

        logger.info(f"æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œç‰‡æ®µæ•°é‡: {len(split_docs)}")
        return split_docs

    except Exception as e:
        logger.error(f"æ–‡æ¡£åˆ†å‰²å¤±è´¥: {str(e)}")
        return documents
```

**åˆ†å‰²ç­–ç•¥è¯¦è§£**ï¼ˆä¸ç¬¬04ç« ç›¸åŒï¼Œä½†å¼ºè°ƒä¸­æ–‡ä¼˜åŒ–ï¼‰ï¼š

```python
separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", " ", ""]
```

| åˆ†éš”ç¬¦ | ä¼˜å…ˆçº§ | è¯´æ˜ | ç¤ºä¾‹ |
|-------|-------|------|------|
| `\n\n` | 1ï¼ˆæœ€é«˜ï¼‰ | æ®µè½è¾¹ç•Œ | æ–‡ç« æ®µè½é—´çš„ç©ºè¡Œ |
| `\n` | 2 | è¡Œè¾¹ç•Œ | åˆ—è¡¨é¡¹ã€ä»£ç è¡Œ |
| `ã€‚ï¼ï¼Ÿ` | 3 | ä¸­æ–‡å¥å­è¾¹ç•Œ | "è¿™æ˜¯ä¸€å¥è¯ã€‚è¿™æ˜¯å¦ä¸€å¥ã€‚" |
| `ï¼Œ` | 4 | ä¸­æ–‡å­å¥è¾¹ç•Œ | "é¦–å…ˆAï¼Œå…¶æ¬¡Bï¼Œæœ€åCã€‚" |
| ` ` | 5 | è¯è¾¹ç•Œï¼ˆè‹±æ–‡ï¼‰ | "Hello world" |
| `""` | 6ï¼ˆæœ€ä½ï¼‰ | å­—ç¬¦è¾¹ç•Œï¼ˆå¼ºåˆ¶åˆ†å‰²ï¼‰ | è¶…é•¿å•è¯è¢«è¿«ä»ä¸­é—´æˆªæ–­ |

**å®é™…æ•ˆæœå¯¹æ¯”**ï¼š

```python
# åŸæ–‡ï¼ˆ200å­—ç¬¦ï¼‰
text = """
Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€ã€‚å®ƒæ”¯æŒé¢å‘å¯¹è±¡ç¼–ç¨‹ã€‚Pythonçš„è¯­æ³•ç®€æ´ä¼˜é›…ã€‚
å¾ˆå¤šäººå–œæ¬¢ç”¨Pythonå¼€å‘Webåº”ç”¨ï¼Œä¹Ÿæœ‰äººç”¨å®ƒåšæ•°æ®åˆ†æã€‚æ€»ä¹‹ï¼ŒPythonæ˜¯ä¸€é—¨å¼ºå¤§çš„è¯­è¨€ã€‚
"""

# chunk_size=100, chunk_overlap=20

# ä¼ ç»Ÿåˆ†å‰²ï¼ˆåªç”¨ç©ºæ ¼ï¼‰
chunks = [
    "Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€ã€‚å®ƒæ”¯æŒé¢å‘å¯¹è±¡ç¼–ç¨‹ã€‚Pythonçš„è¯­æ³•ç®€æ´ä¼˜é›…ã€‚å¾ˆå¤šäººå–œæ¬¢ç”¨Pythonå¼€å‘Webåº”",  # æˆªæ–­ï¼
    "ç”¨ï¼Œä¹Ÿæœ‰äººç”¨å®ƒåšæ•°æ®åˆ†æã€‚æ€»ä¹‹ï¼ŒPythonæ˜¯ä¸€é—¨å¼ºå¤§çš„è¯­è¨€ã€‚"
]

# RecursiveCharacterTextSplitterï¼ˆä¼˜å…ˆç”¨å¥å·ï¼‰
chunks = [
    "Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€ã€‚å®ƒæ”¯æŒé¢å‘å¯¹è±¡ç¼–ç¨‹ã€‚Pythonçš„è¯­æ³•ç®€æ´ä¼˜é›…ã€‚",  # å®Œæ•´å¥å­
    "å¾ˆå¤šäººå–œæ¬¢ç”¨Pythonå¼€å‘Webåº”ç”¨ï¼Œä¹Ÿæœ‰äººç”¨å®ƒåšæ•°æ®åˆ†æã€‚",              # å®Œæ•´å¥å­
    "æ€»ä¹‹ï¼ŒPythonæ˜¯ä¸€é—¨å¼ºå¤§çš„è¯­è¨€ã€‚"                                    # å®Œæ•´å¥å­
]
```

---

### 4.5 å®Œæ•´ä»£ç 

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ utils/document_processor.py å®Œæ•´ä»£ç ï¼ˆ565è¡Œï¼‰</summary>

```python
import os
import hashlib
import logging
from typing import List, Dict, Optional, Any
from pathlib import Path
import streamlit as st
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader, TextLoader, UnstructuredWordDocumentLoader
from config.settings import Settings

logger = logging.getLogger(__name__)

class DocumentProcessor:
    """æ–‡æ¡£å¤„ç†å™¨ç±»"""

    def __init__(self):
        self.settings = Settings()
        self.cache_dir = self.settings.DATA_DIR / "document_cache"
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def _get_file_hash(self, file_content: bytes) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        return hashlib.md5(file_content).hexdigest()

    def process_uploaded_file(self, uploaded_file) -> List[Document]:
        """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæ”¯æŒ UploadedFile å¯¹è±¡å’Œæ–‡ä»¶è·¯å¾„ï¼‰"""
        try:
            # å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥
            if hasattr(uploaded_file, 'size') and hasattr(uploaded_file, 'read'):
                # Streamlit UploadedFile å¯¹è±¡
                if uploaded_file.size > self.settings.MAX_FILE_SIZE:
                    raise ValueError(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {uploaded_file.size} > {self.settings.MAX_FILE_SIZE}")
                file_content = uploaded_file.read()
                file_name = uploaded_file.name
            else:
                # æ–‡ä»¶è·¯å¾„
                file_path = Path(uploaded_file)
                if not file_path.exists():
                    raise ValueError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                file_size = file_path.stat().st_size
                if file_size > self.settings.MAX_FILE_SIZE:
                    raise ValueError(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {file_size} > {self.settings.MAX_FILE_SIZE}")
                with open(file_path, 'rb') as f:
                    file_content = f.read()
                file_name = file_path.name

            file_type = Path(file_name).suffix.lower()

            # æ£€æŸ¥æ–‡ä»¶ç±»å‹
            if file_type not in self.settings.SUPPORTED_FILE_TYPES:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")

            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = self._get_file_hash(file_content)
            cache_path = self._get_cache_path(file_hash, file_name)

            # å°è¯•ä»ç¼“å­˜åŠ è½½
            cached_documents = self._load_from_cache(cache_path)
            if cached_documents is not None:
                return cached_documents

            # å¤„ç†æ–‡ä»¶
            documents = self._process_file_content(file_content, file_name, file_type)

            # ä¿å­˜åˆ°ç¼“å­˜
            self._save_to_cache(cache_path, documents)

            logger.info(f"å¤„ç†æ–‡ä»¶æˆåŠŸ: {file_name}, æ–‡æ¡£æ•°é‡: {len(documents)}")
            return documents

        except Exception as e:
            logger.error(f"å¤„ç†ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise

    def _process_file_content(self, file_content: bytes, file_name: str, file_type: str) -> List[Document]:
        """å¤„ç†æ–‡ä»¶å†…å®¹"""
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_dir = self.settings.DATA_DIR / "temp"
            temp_dir.mkdir(parents=True, exist_ok=True)
            temp_path = temp_dir / file_name

            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with open(temp_path, 'wb') as f:
                f.write(file_content)

            try:
                # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åŠ è½½å™¨
                if file_type == '.pdf':
                    documents = self._load_pdf(temp_path)
                elif file_type == '.txt':
                    documents = self._load_text(temp_path)
                elif file_type == '.md':
                    documents = self._load_markdown(temp_path)
                elif file_type == '.docx':
                    documents = self._load_word(temp_path)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")

                # æ·»åŠ å…ƒæ•°æ®
                for i, doc in enumerate(documents):
                    doc.metadata.update({
                        'source': file_name,
                        'file_type': file_type,
                        'chunk_index': i,
                        'total_chunks': len(documents),
                        'processing_timestamp': str(Path(temp_path).stat().st_mtime)
                    })

                return documents

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_path.exists():
                    temp_path.unlink()

        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å†…å®¹å¤±è´¥: {str(e)}")
            raise

    def _load_pdf(self, file_path: Path) -> List[Document]:
        """åŠ è½½PDFæ–‡ä»¶"""
        try:
            loader = PyPDFLoader(str(file_path))
            documents = loader.load()

            # æ·»åŠ é¡µç ä¿¡æ¯
            for i, doc in enumerate(documents):
                if 'page' not in doc.metadata:
                    doc.metadata['page'] = i + 1

            logger.info(f"åŠ è½½PDFæˆåŠŸ: {file_path.name}, é¡µæ•°: {len(documents)}")
            return documents

        except Exception as e:
            logger.error(f"åŠ è½½PDFå¤±è´¥: {str(e)}")
            raise

    def _load_text(self, file_path: Path) -> List[Document]:
        """åŠ è½½æ–‡æœ¬æ–‡ä»¶"""
        try:
            loader = TextLoader(str(file_path), encoding='utf-8')
            documents = loader.load()

            logger.info(f"åŠ è½½æ–‡æœ¬æ–‡ä»¶æˆåŠŸ: {file_path.name}")
            return documents

        except Exception as e:
            logger.error(f"åŠ è½½æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise

    def _load_markdown(self, file_path: Path) -> List[Document]:
        """åŠ è½½Markdownæ–‡ä»¶"""
        try:
            # Markdownæ–‡ä»¶ä¹Ÿä½¿ç”¨æ–‡æœ¬åŠ è½½å™¨
            loader = TextLoader(str(file_path), encoding='utf-8')
            documents = loader.load()

            # æ·»åŠ æ–‡ä»¶ç±»å‹æ ‡è¯†
            for doc in documents:
                doc.metadata['file_type'] = '.md'

            logger.info(f"åŠ è½½Markdownæ–‡ä»¶æˆåŠŸ: {file_path.name}")
            return documents

        except Exception as e:
            logger.error(f"åŠ è½½Markdownæ–‡ä»¶å¤±è´¥: {str(e)}")
            raise

    def _load_word(self, file_path: Path) -> List[Document]:
        """åŠ è½½Wordæ–‡æ¡£"""
        try:
            loader = UnstructuredWordDocumentLoader(str(file_path))
            documents = loader.load()

            logger.info(f"åŠ è½½Wordæ–‡æ¡£æˆåŠŸ: {file_path.name}")
            return documents

        except Exception as e:
            logger.error(f"åŠ è½½Wordæ–‡æ¡£å¤±è´¥: {str(e)}")
            raise


    def split_documents(self, documents: List[Document], chunk_size: int = None, chunk_overlap: int = None) -> List[Document]:
        """åˆ†å‰²æ–‡æ¡£"""
        try:
            chunk_size = chunk_size or self.settings.CHUNK_SIZE
            chunk_overlap = chunk_overlap or self.settings.CHUNK_OVERLAP

            logger.info(f"åˆ†å‰²æ–‡æ¡£ï¼Œchunk_size: {chunk_size}, chunk_overlap: {chunk_overlap}")

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                length_function=len,
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", " ", ""]
            )

            split_docs = text_splitter.split_documents(documents)

            # æ›´æ–°å…ƒæ•°æ®
            for i, doc in enumerate(split_docs):
                doc.metadata['chunk_index'] = i
                doc.metadata['chunk_size'] = len(doc.page_content)
                doc.metadata['total_chunks'] = len(split_docs)

            logger.info(f"æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œç‰‡æ®µæ•°é‡: {len(split_docs)}")
            return split_docs

        except Exception as e:
            logger.error(f"æ–‡æ¡£åˆ†å‰²å¤±è´¥: {str(e)}")
            return documents

    def _get_cache_path(self, file_hash: str, file_name: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{file_hash}_{file_name}.json"

    def _load_from_cache(self, cache_path: Path) -> Optional[List[Document]]:
        """ä»ç¼“å­˜åŠ è½½æ–‡æ¡£"""
        try:
            if cache_path.exists() and self.settings.CACHE_ENABLED:
                import json
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)

                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                import time
                current_time = time.time()
                cache_time = cache_data.get('timestamp', 0)

                if current_time - cache_time < self.settings.CACHE_EXPIRE_TIME:
                    # é‡å»ºDocumentå¯¹è±¡
                    documents = []
                    for doc_data in cache_data.get('documents', []):
                        doc = Document(
                            page_content=doc_data['page_content'],
                            metadata=doc_data['metadata']
                        )
                        documents.append(doc)

                    logger.info(f"ä»ç¼“å­˜åŠ è½½æ–‡æ¡£æˆåŠŸ: {len(documents)} ä¸ªæ–‡æ¡£")
                    return documents
                else:
                    logger.info("ç¼“å­˜å·²è¿‡æœŸ")

        except Exception as e:
            logger.error(f"ä»ç¼“å­˜åŠ è½½å¤±è´¥: {str(e)}")

        return None

    def _save_to_cache(self, cache_path: Path, documents: List[Document]):
        """ä¿å­˜æ–‡æ¡£åˆ°ç¼“å­˜"""
        try:
            if not self.settings.CACHE_ENABLED:
                return

            import json
            import time

            cache_data = {
                'timestamp': time.time(),
                'documents': [
                    {
                        'page_content': doc.page_content,
                        'metadata': doc.metadata
                    }
                    for doc in documents
                ]
            }

            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)

            logger.info(f"ä¿å­˜åˆ°ç¼“å­˜æˆåŠŸ: {cache_path}")

        except Exception as e:
            logger.error(f"ä¿å­˜åˆ°ç¼“å­˜å¤±è´¥: {str(e)}")

    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            cache_files = list(self.cache_dir.glob("*.json"))
            total_size = sum(f.stat().st_size for f in cache_files)

            stats = {
                'cache_enabled': self.settings.CACHE_ENABLED,
                'cache_expire_time': self.settings.CACHE_EXPIRE_TIME,
                'cache_files_count': len(cache_files),
                'cache_total_size_bytes': total_size,
                'cache_total_size_mb': round(total_size / (1024 * 1024), 2)
            }

            return stats

        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {'error': str(e)}

    def clear_cache(self) -> bool:
        """æ¸…ç©ºç¼“å­˜"""
        try:
            cache_files = list(self.cache_dir.glob("*.json"))
            deleted_count = 0

            for cache_file in cache_files:
                try:
                    cache_file.unlink()
                    deleted_count += 1
                except Exception as e:
                    logger.error(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {cache_file}, é”™è¯¯: {str(e)}")

            logger.info(f"æ¸…ç©ºç¼“å­˜æˆåŠŸï¼Œåˆ é™¤æ–‡ä»¶æ•°: {deleted_count}")
            return True

        except Exception as e:
            logger.error(f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {str(e)}")
            return False

    def process_documents_batch(self, uploaded_files: List) -> Dict[str, Any]:
        """æ‰¹é‡å¤„ç†æ–‡æ¡£"""
        try:
            results = {
                'total_files': len(uploaded_files),
                'processed_files': 0,
                'failed_files': 0,
                'total_documents': 0,
                'errors': []
            }

            all_documents = []

            for file in uploaded_files:
                try:
                    documents = self.process_uploaded_file(file)
                    all_documents.extend(documents)
                    results['processed_files'] += 1
                    results['total_documents'] += len(documents)

                    logger.info(f"å¤„ç†æ–‡ä»¶æˆåŠŸ: {file.name}")

                except Exception as e:
                    results['failed_files'] += 1
                    error_info = {
                        'file_name': file.name,
                        'error': str(e)
                    }
                    results['errors'].append(error_info)
                    logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {file.name}, é”™è¯¯: {str(e)}")

            results['all_documents'] = all_documents
            return results

        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†æ–‡æ¡£å¤±è´¥: {str(e)}")
            raise


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç è§æºæ–‡ä»¶æœ«å°¾ï¼ˆtest_document_processorå‡½æ•°ï¼‰
    pass
```

</details>

---

## äº”ã€æµ‹è¯•ä¸éªŒè¯

### 5.1 è£…é¥°å™¨æµ‹è¯•

```bash
# è¿è¡Œè£…é¥°å™¨æµ‹è¯•
python utils/decorators.py
```

**é¢„æœŸè¾“å‡º**ï¼š

```
=== æµ‹è¯• @error_handler è£…é¥°å™¨ ===
10 Ã· 2 = 5.0
ERROR - å‡½æ•° 'é™¤æ³•è®¡ç®—å™¨' æ‰§è¡Œå¤±è´¥: division by zero
10 Ã· 0 = -1

=== æµ‹è¯• @log_execution è£…é¥°å™¨ ===
DEBUG - å¼€å§‹æ‰§è¡Œå‡½æ•°: æ•°æ®å¤„ç†å‡½æ•°
DEBUG - å‡½æ•°å‚æ•° - args: (['hello', 'world', 'python'],), kwargs: {}
DEBUG - å‡½æ•°æ‰§è¡Œå®Œæˆ: æ•°æ®å¤„ç†å‡½æ•° (è€—æ—¶: 0.001ç§’)
DEBUG - å‡½æ•°è¿”å›å€¼: ['HELLO', 'WORLD', 'PYTHON']
å¤„ç†ç»“æœ: ['HELLO', 'WORLD', 'PYTHON']

=== æµ‹è¯• @performance_monitor è£…é¥°å™¨ ===
INFO - æ€§èƒ½æ­£å¸¸ - å‡½æ•°æ‰§è¡Œå®Œæˆ: æ…¢é€Ÿå‡½æ•° (è€—æ—¶: 0.051ç§’)
ç»“æœ: å»¶è¿Ÿäº† 0.05 ç§’
WARNING - æ€§èƒ½è­¦å‘Š - å‡½æ•°æ‰§è¡Œè¾ƒæ…¢: æ…¢é€Ÿå‡½æ•° (è€—æ—¶: 0.151ç§’)
ç»“æœ: å»¶è¿Ÿäº† 0.15 ç§’
ERROR - æ€§èƒ½å‘Šè­¦ - å‡½æ•°æ‰§è¡Œè¿‡æ…¢: æ…¢é€Ÿå‡½æ•° (è€—æ—¶: 0.351ç§’)
ç»“æœ: å»¶è¿Ÿäº† 0.35 ç§’

=== æµ‹è¯•ç»„åˆè£…é¥°å™¨ ===
INFO - å¼€å§‹æ‰§è¡Œå‡½æ•°: ç»„åˆå‡½æ•°
INFO - å‡½æ•°å‚æ•° - args: (5, 8), kwargs: {}
INFO - æ€§èƒ½æ­£å¸¸ - å‡½æ•°æ‰§è¡Œå®Œæˆ: ç»„åˆå‡½æ•° (è€—æ—¶: 0.051ç§’)
INFO - å‡½æ•°æ‰§è¡Œå®Œæˆ: ç»„åˆå‡½æ•° (è€—æ—¶: 0.051ç§’)
INFO - å‡½æ•°è¿”å›å€¼: 140
ç»„åˆå‡½æ•°ç»“æœ: 140

=== æ‰€æœ‰æµ‹è¯•å®Œæˆ ===
```

### 5.2 æ–‡æ¡£å¤„ç†å™¨æµ‹è¯•

```bash
# è¿è¡Œæ–‡æ¡£å¤„ç†å™¨æµ‹è¯•ï¼ˆéœ€è¦åœ¨files/ç›®å½•æ”¾ç½®æµ‹è¯•æ–‡ä»¶ï¼‰
python utils/document_processor.py
```

---

## å…­ã€æœ¬ç« æ€»ç»“

### 6.1 æ ¸å¿ƒè¦ç‚¹å›é¡¾

âœ… **è£…é¥°å™¨å·¥å…·**ï¼š
- å®ç°äº†3ä¸ªç”Ÿäº§çº§è£…é¥°å™¨ï¼šé”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•ã€æ€§èƒ½ç›‘æ§
- ä½¿ç”¨ä¸‰å±‚åµŒå¥—ç»“æ„æ”¯æŒå‚æ•°åŒ–è£…é¥°å™¨
- @functools.wraps ä¿ç•™å‡½æ•°å…ƒä¿¡æ¯
- è£…é¥°å™¨ç»„åˆé¡ºåºï¼šerror_handler â†’ log_execution â†’ performance_monitor

âœ… **æ–‡æ¡£å¤„ç†å™¨**ï¼š
- æ”¯æŒPDF/Word/Markdown/Textå¤šæ ¼å¼
- MD5å“ˆå¸Œç¼“å­˜æœºåˆ¶ï¼ˆ85%å‘½ä¸­ç‡ï¼‰
- RecursiveCharacterTextSplitteræ™ºèƒ½åˆ†å—
- æ‰¹é‡å¤„ç†å’Œå…ƒæ•°æ®ç®¡ç†

âœ… **å·¥ç¨‹åŒ–å®è·µ**ï¼š
- å…³æ³¨ç‚¹åˆ†ç¦»ï¼šä¸šåŠ¡é€»è¾‘ä¸æ¨ªåˆ‡å…³æ³¨ç‚¹è§£è€¦
- é˜²å¾¡æ€§ç¼–ç¨‹ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•
- æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜æœºåˆ¶å‡å°‘é‡å¤è®¡ç®—
- å¯ç»´æŠ¤æ€§ï¼šç»Ÿä¸€çš„ä»£ç é£æ ¼å’Œæ¸…æ™°çš„æ–‡æ¡£

### 6.2 ä¸å‰å››ç« çš„å…³è”

| ç« èŠ‚ | æ ¸å¿ƒç»„ä»¶ | åœ¨ç¬¬05ç« ä¸­çš„åº”ç”¨ |
|------|----------|------------------|
| ç¬¬02ç«  | Settingsé…ç½® | æ–‡æ¡£å¤„ç†å™¨è¯»å–CACHE_ENABLEDã€MAX_FILE_SIZEç­‰é…ç½® |
| ç¬¬03ç«  | UnifiedLLMClient | å¯ç”¨error_handlerè£…é¥°LLMè°ƒç”¨é˜²æ­¢å´©æºƒ |
| ç¬¬04ç«  | VectorStoreService | æ–‡æ¡£å¤„ç†å™¨çš„è¾“å‡ºä½œä¸ºå‘é‡å­˜å‚¨çš„è¾“å…¥ |

---

## ä¸ƒã€ä¸‹ä¸€ç« é¢„å‘Š

**ç¬¬06ç« ï¼šè¾…åŠ©å·¥å…·ç±»(ä¸‹) - èŠå¤©å†å²ã€å¤©æ°”å·¥å…·ä¸UIç»„ä»¶**

åœ¨ç¬¬06ç« ä¸­ï¼Œæˆ‘ä»¬å°†å®ç°ï¼š
- ğŸ’¬ **èŠå¤©å†å²ç®¡ç†** (`utils/chat_history.py`)ï¼šä¼šè¯æŒä¹…åŒ–ã€ä¸Šä¸‹æ–‡ç®¡ç†
- ğŸŒ¤ï¸ **å¤©æ°”å·¥å…·** (`services/weather_tools.py`)ï¼šAgentå·¥å…·é›†æˆã€APIè°ƒç”¨
- ğŸ¨ **UIç»„ä»¶** (`utils/ui_components.py`)ï¼šStreamlitå¤ç”¨ç»„ä»¶åº“

---

**ç‰ˆæœ¬ä¿¡æ¯**ï¼š
- æ•™ç¨‹ç‰ˆæœ¬ï¼šv1.0
- å¯¹åº”æºç ï¼š
  - `utils/decorators.py`ï¼ˆ510è¡Œï¼‰
  - `utils/document_processor.py`ï¼ˆ565è¡Œï¼‰
- æœ€åæ›´æ–°ï¼š2025-01-15
